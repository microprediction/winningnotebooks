{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKCJZk093H27s+5QsT3irc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microprediction/winningnotebooks/blob/main/LLM_Quinellas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C_4E5p8fd80E",
        "outputId": "8674ca57-0f67-46c6-a351-0357590678c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting winning\n",
            "  Downloading winning-1.0.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from winning) (1.26.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from winning) (7.4.4)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (from winning) (1.0.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from winning) (0.44.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.2)\n",
            "Downloading winning-1.0.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: winning\n",
            "Successfully installed winning-1.0.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install winning\n",
        "!pip install pandas\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Luce's Choice Axiom versus the Standard Normal Race model\n",
        "The methodology is as follows.\n",
        "\n",
        "1.   Ask an LLM to assign probabilities $p_i$ to a set A of tokens\n",
        "2.   Ask an LLM to assign probabilities to a subset $B \\subset A$ of tokens\n",
        "\n",
        "We then try to predict the subset probabilities in two ways:\n",
        "\n",
        "1.   A simple renormalization (Luce Choice Axiom):  $p_i/(\\sum_{j\\in B} p_j)$\n",
        "2.   The Standard Normal Race model: Set $X_i \\sim N(a_i,1)$ where $a_i$ are calibrated to the $p_i$ using the ability transform.  \n",
        "\n",
        "We then compare the errors.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "82THYxZp-nI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A contest model for choice\n",
        "\n",
        "Luce is trivial. Let's just implement the second here using the `winning` package:;"
      ],
      "metadata": {
        "id": "0etgB1K41-jT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from winning.std_calibration import std_state_price_implied_ability, STD_UNIT, STD_L, STD_SCALE, std_ability_implied_state_prices\n",
        "def ability_implied_subrace_probabilities(race:dict, runners:[str])-> dict:\n",
        "     #   Subrace probabilities\n",
        "     probs = list(race.values())\n",
        "     names = list(race.keys())\n",
        "     abilities = std_state_price_implied_ability(probs, unit=STD_UNIT, L=STD_L, scale=STD_SCALE)\n",
        "     sub_names = [nm for nm in names if nm in runners]\n",
        "     sub_abil = [a for nm, a in zip(names,abilities) if nm in runners]\n",
        "     sub_prob = implied_probabilities = std_ability_implied_state_prices(ability=sub_abil,unit=STD_UNIT, L=STD_L, scale=STD_SCALE)\n",
        "     implied = dict( zip(sub_names,sub_prob) )\n",
        "     return implied\n",
        "\n",
        "\n",
        "race = {'red':0.5,'green':0.3,'blue':0.2}\n",
        "\n",
        "runners = ['green','red']\n",
        "implied = ability_implied_subrace_probabilities(race,runners )\n",
        "implied"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlmF3AWf2Ev_",
        "outputId": "2b422ca4-1d34-4d22-8f3c-93f4dd0933eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'red': 0.6169905666139499, 'green': 0.38396120015303187}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quinella pricing"
      ],
      "metadata": {
        "id": "BmW_yeMjam_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from winning.lattice_conventions import STD_L, STD_A\n",
        "from winning.lattice import skew_normal_density, densities_from_offsets, get_the_rest, _loser_of_two_pdf,\\\n",
        "    beats, winner_of_many, cdf_to_pdf\n",
        "from winning.lattice_calibration import state_price_implied_ability\n",
        "\n",
        "\n",
        "def compute_skew_normal_quinellas(p:[float], L=551, a=0):\n",
        "    \"\"\" Produce quinella table, and also return densities\n",
        "\n",
        "    :param p:  Vector of state prices\n",
        "    :param L:  500 by default, half that is probably fine\n",
        "    :return: quinellas, densities\n",
        "    \"\"\"\n",
        "\n",
        "    # Calibration\n",
        "    unit = 1.0\n",
        "    density = skew_normal_density(L=L, unit=unit, loc=0, scale=50.0, a=a)\n",
        "    offsets = state_price_implied_ability(prices=p, density=density)\n",
        "    densities = densities_from_offsets(density, offsets)\n",
        "    densityAll, multiplicityAll = winner_of_many(densities)\n",
        "\n",
        "    n = len(p)\n",
        "    quinellas = np.ndarray(shape=(n, n))\n",
        "    for h0 in range(n):\n",
        "        density0 = densities[h0]\n",
        "        cdfRest0, multiplicityRest0 = get_the_rest(density=density0, densityAll=densityAll,\n",
        "                                                   multiplicityAll=multiplicityAll, cdf=None, cdfAll=None)\n",
        "        for h1 in range(n):\n",
        "            if h1 > h0:\n",
        "                density1 = densities[h1]\n",
        "                cdfRest01, multiplicityRest01 = get_the_rest(density=density1, densityAll=None,\n",
        "                                                             multiplicityAll=multiplicityRest0, cdf=None,\n",
        "                                                             cdfAll=cdfRest0)\n",
        "                pdfRest01 = cdf_to_pdf(cdfRest01)\n",
        "                loser01, loser_multiplicity01 = _loser_of_two_pdf(density0, density1)\n",
        "                quinellas[h0, h1] = 1 / beats(loser01, loser_multiplicity01, pdfRest01, multiplicityRest01)\n",
        "                quinellas[h1, h0] = quinellas[h0, h1]\n",
        "    return quinellas, densities\n",
        "\n",
        "q,_ = compute_skew_normal_quinellas(p=[0.5,0.3,0.1,0.1,0.1,0.001,0.001,0.001,0.001,0.001,0.001])\n",
        "q[:4,:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pVQBEnaDaofR",
        "outputId": "dcdfd585-8b8f-48d3-dd1c-dc9e790c2178"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  3.01759035,  8.21247528,  8.21247528],\n",
              "       [ 3.01759035,  1.        , 14.55937804, 14.55937804],\n",
              "       [ 8.21247528, 14.55937804,  1.        , 42.33440703],\n",
              "       [ 8.21247528, 14.55937804, 42.33440703,  1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_harville_quinellas(p):\n",
        "    \"\"\"\n",
        "    Compute Harville Quinellas (joint probabilities for unordered pairs) from individual probabilities assuming independence.\n",
        "\n",
        "    Args:\n",
        "        p (list of float): List of individual probabilities for each state/event. Should sum to <=1.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary where keys are frozensets representing unordered pairs of states,\n",
        "              and values are the joint probabilities P({i, j}).\n",
        "    \"\"\"\n",
        "    from itertools import combinations\n",
        "\n",
        "    n = len(p)\n",
        "    quinellas = {}\n",
        "\n",
        "    # Compute unnormalized joint probabilities\n",
        "    for i, j in combinations(range(n), 2):\n",
        "        joint_prob = p[i] * p[j]\n",
        "        quinellas[frozenset([i, j])] = joint_prob\n",
        "\n",
        "    # Normalize the joint probabilities so that their sum equals the total probability of any two events occurring\n",
        "    total_joint_prob = sum(quinellas.values())\n",
        "    if total_joint_prob > 0:\n",
        "        quinellas = {pair: prob / total_joint_prob for pair, prob in quinellas.items()}\n",
        "\n",
        "    return quinellas\n",
        "\n",
        "compute_harville_quinellas(p=[0.5,0.3,0.2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUgn9e5CheyC",
        "outputId": "83fb21b4-ebe0-4786-ae71-5d67c5058320"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{frozenset({0, 1}): 0.48387096774193544,\n",
              " frozenset({0, 2}): 0.32258064516129037,\n",
              " frozenset({1, 2}): 0.1935483870967742}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers numpy pandas scipy"
      ],
      "metadata": {
        "id": "ODgmK7QPcHQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single state selection probabilities"
      ],
      "metadata": {
        "id": "JyocXz9mex_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Define an expanded list of single-word Western U.S. states\n",
        "single_word_states = [\n",
        "    'california', 'oregon', 'washington', 'arizona', 'nevada',\n",
        "    'utah', 'idaho', 'montana', 'wyoming', 'colorado',\n",
        "    'new mexico', 'texas', 'oklahoma', 'kansas', 'south dakota',\n",
        "    'north dakota', 'nebraska', 'iowa', 'missouri', 'arkansas'\n",
        "]\n",
        "\n",
        "# Filter to include only single-word states to avoid tokenizer issues\n",
        "single_word_states = [state for state in single_word_states if ' ' not in state]\n",
        "\n",
        "# Define the sentence template with one state fixed and one [MASK]\n",
        "fixed_state = 'california'\n",
        "sentence_template = f\"I visited the state of {fixed_state.capitalize()} and [MASK] last year, and they are my two favorite states in the United States.\"\n",
        "\n",
        "# Step 1: Get Individual Probabilities (P(i))\n",
        "probs_individual = fill_in_missing_word(sentence=sentence_template, exclude_words=None, top_k=200)\n",
        "\n",
        "# Ensure all state names are in lowercase to match the list\n",
        "probs_individual = {k.lower(): v for k, v in probs_individual.items()}\n",
        "\n",
        "# Step 2: Filter probabilities to only include our single-word states\n",
        "probs_individual_filtered = {state: probs_individual[state] for state in single_word_states if state in probs_individual}\n",
        "\n",
        "# Check if any states are missing\n",
        "missing_states = set(single_word_states) - set(probs_individual_filtered.keys())\n",
        "if missing_states:\n",
        "    print(f\"Warning: The following states were not predicted by BERT and will be excluded: {missing_states}\")\n",
        "\n",
        "# Step 3: Normalize the probabilities to sum to 1\n",
        "total_prob_individual = sum(probs_individual_filtered.values())\n",
        "if total_prob_individual == 0:\n",
        "    raise ValueError(\"Total individual probability is zero. Check the BERT predictions.\")\n",
        "probs_individual_normalized = {state: prob / total_prob_individual for state, prob in probs_individual_filtered.items()}\n",
        "\n",
        "# Display top states by probability\n",
        "df_individual = pd.DataFrame(\n",
        "    sorted(probs_individual_normalized.items(), key=lambda x: x[1], reverse=True),\n",
        "    columns=['State', 'Probability']\n",
        ")\n",
        "print(\"Individual Probabilities (P(i)):\")\n",
        "print(df_individual)\n",
        "print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4dwhX91kLLu",
        "outputId": "12e1988a-18c0-49fe-94b5-b3893e9aa0d7"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Individual Probabilities (P(i)):\n",
            "         State  Probability\n",
            "0      arizona     0.413279\n",
            "1       nevada     0.189528\n",
            "2       oregon     0.173016\n",
            "3        texas     0.060147\n",
            "4     colorado     0.034071\n",
            "5        idaho     0.030942\n",
            "6      wyoming     0.020346\n",
            "7         utah     0.016122\n",
            "8     arkansas     0.013266\n",
            "9      montana     0.012060\n",
            "10  california     0.009661\n",
            "11      kansas     0.007988\n",
            "12  washington     0.005856\n",
            "13    nebraska     0.005247\n",
            "14        iowa     0.005216\n",
            "15    oklahoma     0.002860\n",
            "16    missouri     0.000395\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditiona state probabilities"
      ],
      "metadata": {
        "id": "_Y-k4G3MkYsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Assuming the initial setup code is already executed:\n",
        "# - single_word_states defined and filtered\n",
        "# - fixed_state defined as 'california'\n",
        "# - sentence_template defined\n",
        "# - probs_individual computed\n",
        "# - probs_individual_filtered computed\n",
        "# - probs_individual_normalized computed and displayed\n",
        "\n",
        "# Step 4: Compute Conditional Probabilities (P(j|i))\n",
        "conditional_probabilities = {}\n",
        "for state_i in single_word_states:\n",
        "    if state_i not in probs_individual_normalized:\n",
        "        continue  # Skip states that were not predicted\n",
        "\n",
        "    # Corrected Sentence: Fix state_i and mask only the second state\n",
        "    sentence = f\"I visited the state of {state_i.capitalize()} and [MASK] last year, and they are my two favourite states in the United States.\"\n",
        "    print(f\"Constructed Sentence for P(j|{state_i}):\")\n",
        "    print(sentence)\n",
        "\n",
        "    # Get predictions for [MASK]\n",
        "    probs_j_given_i = fill_in_missing_word(sentence=sentence, exclude_words=[state_i], top_k=200)\n",
        "\n",
        "    # Ensure all state names are in lowercase to match the list\n",
        "    probs_j_given_i = {k.lower(): v for k, v in probs_j_given_i.items()}\n",
        "\n",
        "    # Filter to include only our single-word states and exclude state_i\n",
        "    probs_j_filtered = {state_j: prob for state_j, prob in probs_j_given_i.items()\n",
        "                        if state_j in single_word_states and state_j != state_i}\n",
        "\n",
        "    # Debug: Print conditional probabilities for each state_i\n",
        "    print(f\"Conditional Probabilities P(j|{state_i}):\")\n",
        "    if not probs_j_filtered:\n",
        "        print(f\"No valid predictions for P(j|{state_i}). Assigning zero probabilities.\\n\")\n",
        "        # Assign zero probabilities for all possible j\n",
        "        conditional_probabilities[state_i] = {state_j: 0 for state_j in single_word_states if state_j != state_i}\n",
        "        continue\n",
        "\n",
        "    # Normalize the conditional probabilities\n",
        "    total_prob_j = sum(probs_j_filtered.values())\n",
        "    if total_prob_j == 0:\n",
        "        print(f\"Warning: No valid predictions for P(j|{state_i}). Assigning zero probabilities.\\n\")\n",
        "        probs_j_normalized = {state_j: 0 for state_j in probs_j_filtered}\n",
        "    else:\n",
        "        probs_j_normalized = {state_j: prob / total_prob_j for state_j, prob in probs_j_filtered.items()}\n",
        "\n",
        "    # Debug: Print normalized conditional probabilities\n",
        "    df_conditional = pd.DataFrame(\n",
        "        sorted(probs_j_normalized.items(), key=lambda x: x[1], reverse=True),\n",
        "        columns=['State_j', 'P(j|i)']\n",
        "    )\n",
        "    print(df_conditional)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    conditional_probabilities[state_i] = probs_j_normalized\n",
        "\n",
        "# Step 5: Compute Exacta Probabilities (P(i, j) = P(i) * P(j|i))\n",
        "exacta_probabilities = {}\n",
        "for state_i, probs_j in conditional_probabilities.items():\n",
        "    for state_j, p_j_given_i in probs_j.items():\n",
        "        exacta_probabilities[(state_i, state_j)] = probs_individual_normalized[state_i] * p_j_given_i\n",
        "\n",
        "# Step 6: Compute Quinella Probabilities (P({i, j}) = P(i, j) + P(j, i))\n",
        "quinella_probabilities = {}\n",
        "for (state_i, state_j), p_ij in exacta_probabilities.items():\n",
        "    # To ensure unordered pairs, use frozenset\n",
        "    pair = frozenset([state_i, state_j])\n",
        "    if pair in quinella_probabilities:\n",
        "        quinella_probabilities[pair] += p_ij\n",
        "    else:\n",
        "        quinella_probabilities[pair] = p_ij\n",
        "\n",
        "# Normalize quinella probabilities\n",
        "total_quinella_prob = sum(quinella_probabilities.values())\n",
        "if total_quinella_prob == 0:\n",
        "    raise ValueError(\"Total quinella probability is zero. Check the exacta probabilities.\")\n",
        "quinella_probabilities_normalized = {pair: prob / total_quinella_prob for pair, prob in quinella_probabilities.items()}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hEn6HwKokyjg",
        "outputId": "b5d206b4-0785-4e21-b98c-d5b443188a3d"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constructed Sentence for P(j|california):\n",
            "I visited the state of California and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|california):\n",
            "       State_j    P(j|i)\n",
            "0      arizona  0.419381\n",
            "1       oregon  0.204331\n",
            "2       nevada  0.165363\n",
            "3        texas  0.060958\n",
            "4     colorado  0.033385\n",
            "5        idaho  0.026155\n",
            "6      wyoming  0.017378\n",
            "7     arkansas  0.014524\n",
            "8      montana  0.013408\n",
            "9         utah  0.012697\n",
            "10  washington  0.009340\n",
            "11      kansas  0.008910\n",
            "12        iowa  0.005633\n",
            "13    nebraska  0.004618\n",
            "14    oklahoma  0.003455\n",
            "15    missouri  0.000464\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|oregon):\n",
            "I visited the state of Oregon and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|oregon):\n",
            "       State_j    P(j|i)\n",
            "0   california  0.347736\n",
            "1   washington  0.317100\n",
            "2        idaho  0.132629\n",
            "3       nevada  0.063299\n",
            "4      montana  0.037887\n",
            "5     colorado  0.024804\n",
            "6         utah  0.024762\n",
            "7        texas  0.014065\n",
            "8      wyoming  0.011623\n",
            "9     nebraska  0.008200\n",
            "10     arizona  0.008105\n",
            "11    oklahoma  0.003390\n",
            "12    missouri  0.002940\n",
            "13        iowa  0.002766\n",
            "14      kansas  0.000408\n",
            "15    arkansas  0.000287\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|washington):\n",
            "I visited the state of Washington and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|washington):\n",
            "       State_j    P(j|i)\n",
            "0       oregon  0.822113\n",
            "1        idaho  0.114679\n",
            "2   california  0.020602\n",
            "3      montana  0.014862\n",
            "4      wyoming  0.006677\n",
            "5      arizona  0.006308\n",
            "6         iowa  0.003562\n",
            "7         utah  0.003175\n",
            "8     colorado  0.002453\n",
            "9        texas  0.002089\n",
            "10      nevada  0.001198\n",
            "11      kansas  0.000850\n",
            "12    nebraska  0.000640\n",
            "13    arkansas  0.000356\n",
            "14    missouri  0.000249\n",
            "15    oklahoma  0.000187\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|arizona):\n",
            "I visited the state of Arizona and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|arizona):\n",
            "       State_j    P(j|i)\n",
            "0   california  0.431406\n",
            "1       nevada  0.263664\n",
            "2         utah  0.096637\n",
            "3        texas  0.060862\n",
            "4     colorado  0.040187\n",
            "5      wyoming  0.025890\n",
            "6      montana  0.023468\n",
            "7        idaho  0.010547\n",
            "8     nebraska  0.009551\n",
            "9       oregon  0.007794\n",
            "10    oklahoma  0.007680\n",
            "11      kansas  0.005696\n",
            "12    missouri  0.005512\n",
            "13        iowa  0.004771\n",
            "14  washington  0.004126\n",
            "15    arkansas  0.002207\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|nevada):\n",
            "I visited the state of Nevada and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|nevada):\n",
            "       State_j    P(j|i)\n",
            "0         utah  0.293535\n",
            "1   california  0.290691\n",
            "2      arizona  0.193268\n",
            "3       oregon  0.065601\n",
            "4      montana  0.061729\n",
            "5        idaho  0.037450\n",
            "6      wyoming  0.024545\n",
            "7     colorado  0.010684\n",
            "8     oklahoma  0.007977\n",
            "9       kansas  0.004284\n",
            "10       texas  0.003252\n",
            "11    nebraska  0.002768\n",
            "12  washington  0.001533\n",
            "13    arkansas  0.001334\n",
            "14    missouri  0.000919\n",
            "15        iowa  0.000432\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|utah):\n",
            "I visited the state of Utah and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|utah):\n",
            "       State_j    P(j|i)\n",
            "0      arizona  0.226791\n",
            "1       nevada  0.172059\n",
            "2     colorado  0.134460\n",
            "3        idaho  0.132028\n",
            "4      wyoming  0.092691\n",
            "5      montana  0.070084\n",
            "6   california  0.062521\n",
            "7        texas  0.027847\n",
            "8       oregon  0.027166\n",
            "9       kansas  0.014817\n",
            "10  washington  0.013763\n",
            "11    nebraska  0.007911\n",
            "12        iowa  0.007456\n",
            "13    oklahoma  0.005879\n",
            "14    arkansas  0.002997\n",
            "15    missouri  0.001530\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|idaho):\n",
            "I visited the state of Idaho and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|idaho):\n",
            "       State_j    P(j|i)\n",
            "0      montana  0.575141\n",
            "1      wyoming  0.097077\n",
            "2       oregon  0.093146\n",
            "3         utah  0.088327\n",
            "4       nevada  0.038123\n",
            "5   washington  0.033488\n",
            "6   california  0.030897\n",
            "7      arizona  0.016697\n",
            "8     colorado  0.004977\n",
            "9     nebraska  0.004623\n",
            "10    oklahoma  0.004544\n",
            "11      kansas  0.004423\n",
            "12       texas  0.003538\n",
            "13        iowa  0.002683\n",
            "14    arkansas  0.001807\n",
            "15    missouri  0.000509\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|montana):\n",
            "I visited the state of Montana and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|montana):\n",
            "       State_j    P(j|i)\n",
            "0      wyoming  0.469759\n",
            "1        idaho  0.445145\n",
            "2       nevada  0.033089\n",
            "3         utah  0.014844\n",
            "4       oregon  0.011227\n",
            "5      arizona  0.009316\n",
            "6     colorado  0.006745\n",
            "7   washington  0.003061\n",
            "8     oklahoma  0.001721\n",
            "9   california  0.001487\n",
            "10    nebraska  0.001380\n",
            "11        iowa  0.000862\n",
            "12       texas  0.000451\n",
            "13      kansas  0.000430\n",
            "14    arkansas  0.000380\n",
            "15    missouri  0.000101\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|wyoming):\n",
            "I visited the state of Wyoming and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|wyoming):\n",
            "       State_j    P(j|i)\n",
            "0      montana  0.487526\n",
            "1         utah  0.158932\n",
            "2     colorado  0.097367\n",
            "3        idaho  0.074147\n",
            "4     nebraska  0.041128\n",
            "5   california  0.034316\n",
            "6      arizona  0.032109\n",
            "7       oregon  0.022241\n",
            "8       nevada  0.015055\n",
            "9   washington  0.008972\n",
            "10    oklahoma  0.007667\n",
            "11       texas  0.007159\n",
            "12      kansas  0.006816\n",
            "13        iowa  0.003831\n",
            "14    arkansas  0.001799\n",
            "15    missouri  0.000937\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|colorado):\n",
            "I visited the state of Colorado and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|colorado):\n",
            "       State_j    P(j|i)\n",
            "0         utah  0.310449\n",
            "1      wyoming  0.190462\n",
            "2   california  0.121618\n",
            "3      arizona  0.093614\n",
            "4      montana  0.069331\n",
            "5       nevada  0.053162\n",
            "6        texas  0.040469\n",
            "7       kansas  0.035538\n",
            "8       oregon  0.022979\n",
            "9     oklahoma  0.018937\n",
            "10    nebraska  0.011442\n",
            "11    arkansas  0.009194\n",
            "12        iowa  0.007901\n",
            "13  washington  0.006740\n",
            "14       idaho  0.005106\n",
            "15    missouri  0.003059\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|texas):\n",
            "I visited the state of Texas and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|texas):\n",
            "       State_j    P(j|i)\n",
            "0     oklahoma  0.377578\n",
            "1      arizona  0.209754\n",
            "2   california  0.137672\n",
            "3     arkansas  0.072420\n",
            "4       kansas  0.035961\n",
            "5         utah  0.032213\n",
            "6     colorado  0.027993\n",
            "7      wyoming  0.021798\n",
            "8     nebraska  0.020678\n",
            "9       oregon  0.018236\n",
            "10     montana  0.014309\n",
            "11        iowa  0.013301\n",
            "12      nevada  0.006576\n",
            "13    missouri  0.005950\n",
            "14       idaho  0.003123\n",
            "15  washington  0.002440\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|oklahoma):\n",
            "I visited the state of Oklahoma and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|oklahoma):\n",
            "       State_j    P(j|i)\n",
            "0        texas  0.435501\n",
            "1       kansas  0.207341\n",
            "2     arkansas  0.144846\n",
            "3     nebraska  0.042058\n",
            "4     colorado  0.032077\n",
            "5         iowa  0.023232\n",
            "6      montana  0.023004\n",
            "7      arizona  0.021290\n",
            "8   california  0.020363\n",
            "9      wyoming  0.019616\n",
            "10    missouri  0.011163\n",
            "11      oregon  0.008855\n",
            "12      nevada  0.004526\n",
            "13        utah  0.002957\n",
            "14       idaho  0.002245\n",
            "15  washington  0.000925\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|kansas):\n",
            "I visited the state of Kansas and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|kansas):\n",
            "       State_j    P(j|i)\n",
            "0     nebraska  0.328115\n",
            "1     oklahoma  0.255186\n",
            "2        texas  0.093090\n",
            "3     missouri  0.072362\n",
            "4         iowa  0.071031\n",
            "5     colorado  0.042094\n",
            "6   california  0.026223\n",
            "7      montana  0.023682\n",
            "8     arkansas  0.018679\n",
            "9         utah  0.016077\n",
            "10     arizona  0.014466\n",
            "11     wyoming  0.013315\n",
            "12       idaho  0.010486\n",
            "13      nevada  0.010436\n",
            "14  washington  0.003186\n",
            "15      oregon  0.001571\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|nebraska):\n",
            "I visited the state of Nebraska and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|nebraska):\n",
            "       State_j    P(j|i)\n",
            "0       kansas  0.475166\n",
            "1      wyoming  0.194851\n",
            "2         iowa  0.097000\n",
            "3     oklahoma  0.060040\n",
            "4       oregon  0.033343\n",
            "5        texas  0.032394\n",
            "6   california  0.030345\n",
            "7     colorado  0.017600\n",
            "8         utah  0.015204\n",
            "9      montana  0.011833\n",
            "10    missouri  0.009064\n",
            "11     arizona  0.007372\n",
            "12    arkansas  0.006099\n",
            "13      nevada  0.005139\n",
            "14       idaho  0.002858\n",
            "15  washington  0.001693\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|iowa):\n",
            "I visited the state of Iowa and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|iowa):\n",
            "       State_j    P(j|i)\n",
            "0     nebraska  0.347770\n",
            "1       kansas  0.156184\n",
            "2     missouri  0.109567\n",
            "3      montana  0.068952\n",
            "4     oklahoma  0.065268\n",
            "5        texas  0.049379\n",
            "6   california  0.030366\n",
            "7       oregon  0.029538\n",
            "8         utah  0.022673\n",
            "9      wyoming  0.022577\n",
            "10    arkansas  0.022554\n",
            "11    colorado  0.019718\n",
            "12     arizona  0.016728\n",
            "13       idaho  0.015101\n",
            "14  washington  0.014085\n",
            "15      nevada  0.009539\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|missouri):\n",
            "I visited the state of Missouri and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|missouri):\n",
            "       State_j    P(j|i)\n",
            "0     arkansas  0.315716\n",
            "1       kansas  0.263779\n",
            "2     oklahoma  0.105216\n",
            "3         iowa  0.089169\n",
            "4     nebraska  0.058265\n",
            "5        texas  0.049377\n",
            "6      arizona  0.040813\n",
            "7      montana  0.033879\n",
            "8     colorado  0.010470\n",
            "9      wyoming  0.008736\n",
            "10      oregon  0.008688\n",
            "11      nevada  0.005593\n",
            "12  california  0.003029\n",
            "13       idaho  0.002692\n",
            "14        utah  0.002654\n",
            "15  washington  0.001923\n",
            "\n",
            "\n",
            "Constructed Sentence for P(j|arkansas):\n",
            "I visited the state of Arkansas and [MASK] last year, and they are my two favourite states in the United States.\n",
            "Conditional Probabilities P(j|arkansas):\n",
            "       State_j    P(j|i)\n",
            "0     oklahoma  0.414442\n",
            "1     missouri  0.147204\n",
            "2        texas  0.113670\n",
            "3     nebraska  0.050477\n",
            "4   california  0.046624\n",
            "5      montana  0.033893\n",
            "6      arizona  0.030943\n",
            "7         iowa  0.026042\n",
            "8        idaho  0.024427\n",
            "9     colorado  0.024068\n",
            "10      nevada  0.021710\n",
            "11      kansas  0.021708\n",
            "12     wyoming  0.020604\n",
            "13        utah  0.019368\n",
            "14      oregon  0.002570\n",
            "15  washington  0.002250\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Compute Theoretical Joint Probabilities Using Harville's Method\n",
        "# Assuming compute_harville_quinellas takes a list of individual probabilities and returns a dict of frozenset pairs\n",
        "p_list = [probs_individual_normalized[state] for state in single_word_states if state in probs_individual_normalized]\n",
        "harville_quinellas = compute_harville_quinellas(p=p_list)"
      ],
      "metadata": {
        "id": "YuOFoIRCljO3"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Compute Theoretical Joint Probabilities Using Skew-Normal Distribution\n",
        "# Assuming skew_normal_quinellas takes a list of individual probabilities and returns a matrix\n",
        "q_matrix, _ = compute_skew_normal_quinellas(p=p_list, L=251, a=0)\n",
        "q_matrix[:4,:4]\n",
        "\n",
        "df_skew = pd.DataFrame([\n",
        "      {'Pair': ', '.join(sorted(pair)), 'Probability_Skew_Normal': prob} for pair, prob in skew_normal_quinellas_named.items()\n",
        "  ])\n",
        "print(\"Skew-Normal Quinellas (First 4 Pairs):\")\n",
        "print(df_skew.head(4))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Normalize skew_normal_quinellas if necessary\n",
        "total_skew = sum(skew_normal_quinellas.values())\n",
        "if total_skew == 0:\n",
        "    print(\"Total skew-normal quinella probability is zero.\")\n",
        "    skew_normal_quinellas_normalized = skew_normal_quinellas_named\n",
        "else:\n",
        "    skew_normal_quinellas_normalized = {pair: prob / total_skew for pair, prob in skew_normal_quinellas_named.items()}\n",
        "\n",
        "# Update df_skew with normalized probabilities\n",
        "df_skew['Probability_Skew_Normal'] = df_skew['Probability_Skew_Normal'].apply(lambda x: x / total_skew if total_skew > 0 else 0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "fx2TDKAhmAQ0",
        "outputId": "8b742225-b06b-4be5-b800-b0972ea3326c"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'skew_normal_quinellas_named' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-5e6a428d755d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m df_skew = pd.DataFrame([\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0;34m{\u001b[0m\u001b[0;34m'Pair'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Probability_Skew_Normal'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskew_normal_quinellas_named\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   ])\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Skew-Normal Quinellas (First 4 Pairs):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'skew_normal_quinellas_named' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert skew_normal_quinellas matrix to quinella_probabilities_skew dict\n",
        "skew_normal_quinellas = {}\n",
        "n = len(p_list)\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        if i != j:\n",
        "            pair = frozenset([single_word_states[i], single_word_states[j]])\n",
        "            try:\n",
        "                skew_normal_quinellas[pair] = 1/q_matrix[i, j]\n",
        "            except IndexError:\n",
        "                print(f\"IndexError for pair {pair}: q_matrix[{i}, {j}] is out of bounds.\")\n",
        "                skew_normal_quinellas[pair] = 0  # Assign zero or handle appropriately\n",
        "\n",
        "# Normalize skew_normal_quinellas\n",
        "total_skew = sum(skew_normal_quinellas.values())\n",
        "if total_skew == 0:\n",
        "    print(\"Total skew-normal quinella probability is zero.\")\n",
        "    skew_normal_quinellas_normalized = skew_normal_quinellas\n",
        "else:\n",
        "    skew_normal_quinellas_normalized = {pair: prob / total_skew for pair, prob in skew_normal_quinellas.items()}\n",
        "\n",
        "skew_normal_quinellas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XF0r_NHdmRb2",
        "outputId": "7047f20b-e5d5-4ba2-ce75-85205cfe54b7"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{frozenset({'california', 'oregon'}): 0.005111879165611478,\n",
              " frozenset({'california', 'washington'}): 0.0002453526736954661,\n",
              " frozenset({'arizona', 'california'}): 0.012871234021167468,\n",
              " frozenset({'california', 'nevada'}): 0.005590418854005174,\n",
              " frozenset({'california', 'utah'}): 0.0005981799373887171,\n",
              " frozenset({'california', 'idaho'}): 0.0010622255374262252,\n",
              " frozenset({'california', 'montana'}): 0.00046341795692141986,\n",
              " frozenset({'california', 'wyoming'}): 0.000734090579772625,\n",
              " frozenset({'california', 'colorado'}): 0.0011566136604260198,\n",
              " frozenset({'california', 'texas'}): 0.0019178390947369147,\n",
              " frozenset({'california', 'oklahoma'}): 0.0001308859625168634,\n",
              " frozenset({'california', 'kansas'}): 0.00032247055220238516,\n",
              " frozenset({'california', 'nebraska'}): 0.00022275021508048992,\n",
              " frozenset({'california', 'iowa'}): 0.0002216060361925625,\n",
              " frozenset({'california', 'missouri'}): 3.4644050245269346e-05,\n",
              " frozenset({'arkansas', 'california'}): 0.0005039169880002704,\n",
              " frozenset({'oregon', 'washington'}): 0.003257918651534623,\n",
              " frozenset({'arizona', 'oregon'}): 0.16879748098328792,\n",
              " frozenset({'nevada', 'oregon'}): 0.07656919555265138,\n",
              " frozenset({'oregon', 'utah'}): 0.008101014121105397,\n",
              " frozenset({'idaho', 'oregon'}): 0.014551154129968975,\n",
              " frozenset({'montana', 'oregon'}): 0.006240819435455953,\n",
              " frozenset({'oregon', 'wyoming'}): 0.00998471575740459,\n",
              " frozenset({'colorado', 'oregon'}): 0.015867315656857086,\n",
              " frozenset({'oregon', 'texas'}): 0.02648473727593525,\n",
              " frozenset({'oklahoma', 'oregon'}): 0.0017178472426422945,\n",
              " frozenset({'kansas', 'oregon'}): 0.004307668041293435,\n",
              " frozenset({'nebraska', 'oregon'}): 0.0029517569338654774,\n",
              " frozenset({'iowa', 'oregon'}): 0.002936288692998723,\n",
              " frozenset({'missouri', 'oregon'}): 0.000504464542983502,\n",
              " frozenset({'arkansas', 'oregon'}): 0.006798856516678696,\n",
              " frozenset({'arizona', 'washington'}): 0.008241973488529336,\n",
              " frozenset({'nevada', 'washington'}): 0.003563496682856969,\n",
              " frozenset({'utah', 'washington'}): 0.0003839407761000853,\n",
              " frozenset({'idaho', 'washington'}): 0.0006796382242788069,\n",
              " frozenset({'montana', 'washington'}): 0.0002978904064574818,\n",
              " frozenset({'washington', 'wyoming'}): 0.0004706243166569987,\n",
              " frozenset({'colorado', 'washington'}): 0.0007397144322536463,\n",
              " frozenset({'texas', 'washington'}): 0.001223875568997887,\n",
              " frozenset({'oklahoma', 'washington'}): 8.473603972613334e-05,\n",
              " frozenset({'kansas', 'washington'}): 0.00020773526779797893,\n",
              " frozenset({'nebraska', 'washington'}): 0.00014380710845850054,\n",
              " frozenset({'iowa', 'washington'}): 0.0001430725416377052,\n",
              " frozenset({'missouri', 'washington'}): 2.2053341364699973e-05,\n",
              " frozenset({'arkansas', 'washington'}): 0.0003237631412000699,\n",
              " frozenset({'arizona', 'nevada'}): 0.18363805093604998,\n",
              " frozenset({'arizona', 'utah'}): 0.020289822587236037,\n",
              " frozenset({'arizona', 'idaho'}): 0.03616597698988042,\n",
              " frozenset({'arizona', 'montana'}): 0.015678798278616825,\n",
              " frozenset({'arizona', 'wyoming'}): 0.02494286122295839,\n",
              " frozenset({'arizona', 'colorado'}): 0.03938767075825741,\n",
              " frozenset({'arizona', 'texas'}): 0.06519555754771474,\n",
              " frozenset({'arizona', 'oklahoma'}): 0.004371158641567792,\n",
              " frozenset({'arizona', 'kansas'}): 0.010866329407690544,\n",
              " frozenset({'arizona', 'nebraska'}): 0.007474722417261369,\n",
              " frozenset({'arizona', 'iowa'}): 0.007435926841328451,\n",
              " frozenset({'arizona', 'missouri'}): 0.0012600476532461074,\n",
              " frozenset({'arizona', 'arkansas'}): 0.017063896073645817,\n",
              " frozenset({'nevada', 'utah'}): 0.008857672825296708,\n",
              " frozenset({'idaho', 'nevada'}): 0.015905344158633816,\n",
              " frozenset({'montana', 'nevada'}): 0.006824499688748404,\n",
              " frozenset({'nevada', 'wyoming'}): 0.010916228134938562,\n",
              " frozenset({'colorado', 'nevada'}): 0.01734303077705515,\n",
              " frozenset({'nevada', 'texas'}): 0.02893610728596716,\n",
              " frozenset({'nevada', 'oklahoma'}): 0.0018794027301412236,\n",
              " frozenset({'kansas', 'nevada'}): 0.00471122900978297,\n",
              " frozenset({'nebraska', 'nevada'}): 0.0032287317332461833,\n",
              " frozenset({'iowa', 'nevada'}): 0.003211817979817167,\n",
              " frozenset({'missouri', 'nevada'}): 0.0005523899131577452,\n",
              " frozenset({'arkansas', 'nevada'}): 0.00743446182278819,\n",
              " frozenset({'idaho', 'utah'}): 0.00167665861511587,\n",
              " frozenset({'montana', 'utah'}): 0.0007279752763416935,\n",
              " frozenset({'utah', 'wyoming'}): 0.0011563394123911862,\n",
              " frozenset({'colorado', 'utah'}): 0.0018264509495271495,\n",
              " frozenset({'texas', 'utah'}): 0.003035406201308075,\n",
              " frozenset({'oklahoma', 'utah'}): 0.00020412997753622238,\n",
              " frozenset({'kansas', 'utah'}): 0.0005054472596776977,\n",
              " frozenset({'nebraska', 'utah'}): 0.00034837440249097304,\n",
              " frozenset({'iowa', 'utah'}): 0.0003465748634053717,\n",
              " frozenset({'missouri', 'utah'}): 5.5058405010750944e-05,\n",
              " frozenset({'arkansas', 'utah'}): 0.0007919971983531503,\n",
              " frozenset({'idaho', 'montana'}): 0.0012945440983635995,\n",
              " frozenset({'idaho', 'wyoming'}): 0.002063055840537179,\n",
              " frozenset({'colorado', 'idaho'}): 0.003268346982367317,\n",
              " frozenset({'idaho', 'texas'}): 0.00544624406139819,\n",
              " frozenset({'idaho', 'oklahoma'}): 0.0003599371396732356,\n",
              " frozenset({'idaho', 'kansas'}): 0.0008964663869783565,\n",
              " frozenset({'idaho', 'nebraska'}): 0.0006162691769913145,\n",
              " frozenset({'idaho', 'iowa'}): 0.0006130648538127171,\n",
              " frozenset({'idaho', 'missouri'}): 9.965278704692352e-05,\n",
              " frozenset({'arkansas', 'idaho'}): 0.0014092492228820305,\n",
              " frozenset({'montana', 'wyoming'}): 0.0008938442753604542,\n",
              " frozenset({'colorado', 'montana'}): 0.0014098464108085833,\n",
              " frozenset({'montana', 'texas'}): 0.0023400449577832406,\n",
              " frozenset({'montana', 'oklahoma'}): 0.00015867889833743993,\n",
              " frozenset({'kansas', 'montana'}): 0.0003918018536823465,\n",
              " frozenset({'montana', 'nebraska'}): 0.0002703813395496019,\n",
              " frozenset({'iowa', 'montana'}): 0.00026898908039965066,\n",
              " frozenset({'missouri', 'montana'}): 4.233548122106239e-05,\n",
              " frozenset({'arkansas', 'montana'}): 0.0006129835472527773,\n",
              " frozenset({'colorado', 'wyoming'}): 0.0022478071464697856,\n",
              " frozenset({'texas', 'wyoming'}): 0.003739390241111512,\n",
              " frozenset({'oklahoma', 'wyoming'}): 0.00024985270384193466,\n",
              " frozenset({'kansas', 'wyoming'}): 0.0006200102017763673,\n",
              " frozenset({'nebraska', 'wyoming'}): 0.0004269224164569476,\n",
              " frozenset({'iowa', 'wyoming'}): 0.00042471173761584734,\n",
              " frozenset({'missouri', 'wyoming'}): 6.800631839294852e-05,\n",
              " frozenset({'arkansas', 'wyoming'}): 0.0009726719614373199,\n",
              " frozenset({'colorado', 'texas'}): 0.005938437407019261,\n",
              " frozenset({'colorado', 'oklahoma'}): 0.0003915511482414243,\n",
              " frozenset({'colorado', 'kansas'}): 0.0009759651176554895,\n",
              " frozenset({'colorado', 'nebraska'}): 0.00067068385606799,\n",
              " frozenset({'colorado', 'iowa'}): 0.0006671935421773194,\n",
              " frozenset({'colorado', 'missouri'}): 0.00010883809215049229,\n",
              " frozenset({'arkansas', 'colorado'}): 0.0015348945387265963,\n",
              " frozenset({'oklahoma', 'texas'}): 0.0006461533442935853,\n",
              " frozenset({'kansas', 'texas'}): 0.001616932094103504,\n",
              " frozenset({'nebraska', 'texas'}): 0.0011091557956257041,\n",
              " frozenset({'iowa', 'texas'}): 0.001103357889329027,\n",
              " frozenset({'missouri', 'texas'}): 0.00018385592500477313,\n",
              " frozenset({'arkansas', 'texas'}): 0.00254867669081619,\n",
              " frozenset({'kansas', 'oklahoma'}): 0.00011095994084933977,\n",
              " frozenset({'nebraska', 'oklahoma'}): 7.702839636463333e-05,\n",
              " frozenset({'iowa', 'oklahoma'}): 7.663779153655202e-05,\n",
              " frozenset({'missouri', 'oklahoma'}): 1.1585994364947778e-05,\n",
              " frozenset({'arkansas', 'oklahoma'}): 0.0001723526838134428,\n",
              " frozenset({'kansas', 'nebraska'}): 0.00018863832581273278,\n",
              " frozenset({'iowa', 'kansas'}): 0.00018767142359353805,\n",
              " frozenset({'kansas', 'missouri'}): 2.917745483122058e-05,\n",
              " frozenset({'arkansas', 'kansas'}): 0.000425961314132231,\n",
              " frozenset({'iowa', 'nebraska'}): 0.00012998111283341008,\n",
              " frozenset({'missouri', 'nebraska'}): 1.9976559093781803e-05,\n",
              " frozenset({'arkansas', 'nebraska'}): 0.0002938338839348627,\n",
              " frozenset({'iowa', 'missouri'}): 1.9871606258877915e-05,\n",
              " frozenset({'arkansas', 'iowa'}): 0.0002923192775442154,\n",
              " frozenset({'arkansas', 'missouri'}): 4.6145609639216834e-05}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_empirical = pd.DataFrame([\n",
        "    {'Pair': ', '.join(pair), 'Probability_Empirical': prob} for pair, prob in quinella_probabilities_normalized.items()\n",
        "])\n",
        "df_empirical.head(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "vP2iBGc6mnaj",
        "outputId": "85a4b23d-ca68-4144-a7cb-6b85e5ad2fc3"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Pair  Probability_Empirical\n",
              "0  arizona, california               0.182343\n",
              "1   california, oregon               0.062138\n",
              "2   california, nevada               0.056692\n",
              "3    texas, california               0.008869"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bc561e6-20e8-490f-9fa5-4438b89e8dd4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pair</th>\n",
              "      <th>Probability_Empirical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>arizona, california</td>\n",
              "      <td>0.182343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>california, oregon</td>\n",
              "      <td>0.062138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>california, nevada</td>\n",
              "      <td>0.056692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>texas, california</td>\n",
              "      <td>0.008869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bc561e6-20e8-490f-9fa5-4438b89e8dd4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3bc561e6-20e8-490f-9fa5-4438b89e8dd4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3bc561e6-20e8-490f-9fa5-4438b89e8dd4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db2b8084-578e-4b38-9a0d-e5204bfbfb0b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db2b8084-578e-4b38-9a0d-e5204bfbfb0b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db2b8084-578e-4b38-9a0d-e5204bfbfb0b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_empirical",
              "summary": "{\n  \"name\": \"df_empirical\",\n  \"rows\": 136,\n  \"fields\": [\n    {\n      \"column\": \"Pair\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 136,\n        \"samples\": [\n          \"utah, montana\",\n          \"arizona, nevada\",\n          \"idaho, nevada\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Probability_Empirical\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022556649391000643,\n        \"min\": 2.218954125607524e-06,\n        \"max\": 0.18234304335814766,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          0.0013088927831368577,\n          0.14559671128550322,\n          0.00827746724981041\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge DataFrames on 'Pair'\n",
        "df_comparison = df_empirical.merge(df_harville, on='Pair', how='outer')\n",
        "df_comparison = df_comparison.merge(df_skew, on='Pair', how='outer')\n",
        "\n",
        "# Fill NaN with 0\n",
        "df_comparison.fillna(0, inplace=True)\n",
        "\n",
        "# Calculate Differences\n",
        "df_comparison['Difference_Harville'] = df_comparison['Probability_Empirical'] - df_comparison['Probability_Harville']\n",
        "df_comparison['Abs_Difference_Harville'] = df_comparison['Difference_Harville'].abs()\n",
        "\n",
        "df_comparison['Difference_Skew_Normal'] = df_comparison['Probability_Empirical'] - df_comparison['Probability_Skew_Normal']\n",
        "df_comparison['Abs_Difference_Skew_Normal'] = df_comparison['Difference_Skew_Normal'].abs()\n",
        "\n",
        "# Calculate RMSE for both models\n",
        "rmse_harville = np.sqrt(np.mean(df_comparison['Difference_Harville'] ** 2))\n",
        "rmse_skew_normal = np.sqrt(np.mean(df_comparison['Difference_Skew_Normal'] ** 2))\n",
        "\n",
        "print(f\"Root Mean Square Error (RMSE) - Harville Quinellas: {rmse_harville:.6f}\")\n",
        "print(f\"Root Mean Square Error (RMSE) - Skew Normal Quinellas: {rmse_skew_normal:.6f}\\n\")\n",
        "\n",
        "# Display the top 10 pairs with the largest absolute differences for Harville\n",
        "print(\"Top 10 Pairs with Largest Absolute Differences (Harville):\")\n",
        "print(df_comparison.sort_values('Abs_Difference_Harville', ascending=False).head(10))\n",
        "\n",
        "# Display the top 10 pairs with the largest absolute differences for Skew Normal Quinella\n",
        "print(\"\\nTop 10 Pairs with Largest Absolute Differences (Skew Normal Quinella):\")\n",
        "print(df_comparison.sort_values('Abs_Difference_Skew_Normal', ascending=False).head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "2DKQy4vJp_wb",
        "outputId": "deed9d69-60b5-4636-b050-2ff62059f6e9"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_skew' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-6439ba823703>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Merge DataFrames on 'Pair'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_comparison\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_empirical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_harville\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pair'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_comparison\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_comparison\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_skew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pair'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Fill NaN with 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_skew' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimental Setup..."
      ],
      "metadata": {
        "id": "VIUlYELKfNgJ"
      }
    }
  ]
}