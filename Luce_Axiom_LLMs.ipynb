{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8KODEvDF2schsYiUY5967",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microprediction/winningnotebooks/blob/main/Luce_Axiom_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C_4E5p8fd80E",
        "outputId": "eca3fb43-020b-4aa8-99fd-316989fab87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: winning in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from winning) (1.26.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from winning) (7.4.4)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (from winning) (1.0.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from winning) (0.44.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install winning\n",
        "!pip install pandas\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Luce's Choice Axiom versus the Ability Transform\n",
        "This notebook considers two different models for inferring preferences. The methodology is as follows. With careful prompt engineering:\n",
        "\n",
        "*   Ask an LLM to assign probabilities to a set A of tokens\n",
        "*   Ask an LLM to assign probabilities to a subset $B \\subset A$ of tokens\n",
        "\n",
        "We then try to predict the subset probabilities in two ways:\n",
        "\n",
        "\n",
        "1.   A simple renormalization\n",
        "2.   Using an contest model\n",
        "\n",
        "We then compare the errors.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "82THYxZp-nI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A contest model for choice\n",
        "\n",
        "Since the first method is trivial, let's just implement the second here:"
      ],
      "metadata": {
        "id": "0etgB1K41-jT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install winning"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SE2nNb1w2BPx",
        "outputId": "7ac4b883-54a2-48a0-d7f0-544f02c3483d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: winning in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from winning) (1.26.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from winning) (7.4.4)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (from winning) (1.0.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from winning) (0.44.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from winning.std_calibration import std_state_price_implied_ability, STD_UNIT, STD_L, STD_SCALE, std_ability_implied_state_prices\n",
        "def ability_implied_subrace_probabilities(race:dict, runners:[str])-> dict:\n",
        "     #   Subrace probabilities\n",
        "     probs = list(race.values())\n",
        "     names = list(race.keys())\n",
        "     abilities = std_state_price_implied_ability(probs, unit=STD_UNIT, L=STD_L, scale=STD_SCALE)\n",
        "     sub_names = [nm for nm in names if nm in runners]\n",
        "     sub_abil = [a for nm, a in zip(names,abilities) if nm in runners]\n",
        "     sub_prob = implied_probabilities = std_ability_implied_state_prices(ability=sub_abil,unit=STD_UNIT, L=STD_L, scale=STD_SCALE)\n",
        "     implied = dict( zip(sub_names,sub_prob) )\n",
        "     return implied\n",
        "\n",
        "\n",
        "race = {'red':0.5,'green':0.3,'blue':0.2}\n",
        "\n",
        "runners = ['green','red']\n",
        "implied = ability_implied_subrace_probabilities(race,runners )\n",
        "implied"
      ],
      "metadata": {
        "id": "rlmF3AWf2Ev_",
        "outputId": "95700699-6aca-49f5-de2d-3c2be6bbaed0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'red': 0.6169905666139499, 'green': 0.38396120015303187}"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments\n",
        "Here's the setup..."
      ],
      "metadata": {
        "id": "jLaevk3yI8DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def fill_in_missing_word(sentence, exclude_words=None, top_k=20):\n",
        "    # Tokenize the input sentence\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "    # Find the index of the masked token\n",
        "    mask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
        "\n",
        "    # Get the model's predictions (logits)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    if exclude_words:\n",
        "        # Get the IDs of the words to exclude\n",
        "        exclude_ids = tokenizer.convert_tokens_to_ids(exclude_words)\n",
        "        # Set their logits to a very low value\n",
        "        logits[0, mask_token_index, exclude_ids] = -float('inf')\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probs = torch.softmax(logits[0, mask_token_index], dim=-1)\n",
        "\n",
        "    # Get the top_k predictions\n",
        "    top_k_probs, top_k_indices = torch.topk(probs, top_k, dim=-1)\n",
        "\n",
        "    # If there's only one mask token, adjust dimensions\n",
        "    if top_k_indices.dim() == 2 and top_k_indices.size(0) == 1:\n",
        "        top_k_indices = top_k_indices.squeeze(0)\n",
        "        top_k_probs = top_k_probs.squeeze(0)\n",
        "\n",
        "    top_k_tokens = tokenizer.convert_ids_to_tokens(top_k_indices.tolist())\n",
        "    top_k_probs = top_k_probs.tolist()\n",
        "\n",
        "    # Store the top predictions in a dictionary\n",
        "    predictions = dict(zip(top_k_tokens, top_k_probs))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "\n",
        "# Luce Axiom Check\n",
        "def luce_check(sentence1, sentence2):\n",
        "    # Get probabilities from both sentences\n",
        "    probs1 = fill_in_missing_word(sentence1, top_k=100)\n",
        "    probs2 = fill_in_missing_word(sentence2, top_k=10)\n",
        "\n",
        "    # Filter out words in sentence2 not present in sentence1\n",
        "    common_tokens = set(probs1.keys()).intersection(set(probs2.keys()))\n",
        "\n",
        "    # Create filtered dictionaries with common tokens\n",
        "    probs1_filtered = {token: probs1[token] for token in common_tokens}\n",
        "    probs2_filtered = {token: probs2[token] for token in common_tokens}\n",
        "\n",
        "    # Store the original scores (unnormalized) before renormalization\n",
        "    original_scores = {token: probs1[token] for token in probs1_filtered}\n",
        "\n",
        "    # Renormalize probs2 so they sum to 1\n",
        "    total_prob2 = sum(probs2_filtered.values())\n",
        "    probs2_normalized = {token: prob / total_prob2 for token, prob in probs2_filtered.items()}\n",
        "\n",
        "    # Renormalize probs1 so they sum to 1\n",
        "    total_prob1 = sum(probs1_filtered.values())\n",
        "    probs1_normalized = {token: prob / total_prob1 for token, prob in probs1_filtered.items()}\n",
        "\n",
        "    # Also add ability implied ...\n",
        "    prob2_ability = ability_implied_subrace_probabilities(race=probs1, runners=common_tokens)\n",
        "\n",
        "\n",
        "    # Merge both into a DataFrame for comparison\n",
        "    df = pd.DataFrame({\n",
        "        'Choice': list(probs1_normalized.keys()),\n",
        "        'Original score': [original_scores[token] for token in probs1_normalized.keys()],\n",
        "        'Luce score': list(probs1_normalized.values()),\n",
        "        'Ability score': [ prob2_ability[token] for token in probs1_normalized.keys()],\n",
        "        'Actual score': [probs2_normalized[token] for token in probs1_normalized.keys()]\n",
        "    })\n",
        "\n",
        "    # Add a column for the empirical / Luce ratio\n",
        "    df['Actual/Luce'] = df['Actual score'] / df['Luce score']\n",
        "    df['Actual/Ability'] = df['Actual score'] / df['Ability score']\n",
        "    df['Ability RMSE'] =  np.sqrt(((df['Actual score'] - df['Ability score']) ** 2).mean())\n",
        "    df['Luce RMSE'] =  np.sqrt(((df['Actual score'] - df['Luce score']) ** 2).mean())\n",
        "    winner = 'Luce' if df['Luce RMSE'].loc[0]<df['Ability RMSE'].loc[0] else 'Ability'\n",
        "    df['Winner'] = winner\n",
        "\n",
        "    df.sort_values('Luce score',inplace=True, ascending=False)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Function to display results\n",
        "def display_predictions(sentence, exclude_words=None):\n",
        "    predictions = fill_in_missing_word(sentence, exclude_words=exclude_words)\n",
        "    sorted_predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(\"Top predictions:\")\n",
        "    for word, score in sorted_predictions:\n",
        "        print(f\"  {word}: {score:.4f}\")\n",
        "    print(\"\\n\")\n",
        "    return sorted_predictions\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIacGX3KI-IG",
        "outputId": "f84e0701-8ff4-435c-c866-c0e544f1fdf7"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eating Choices"
      ],
      "metadata": {
        "id": "GVrd7WWOSHLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My favourite type of fruit or vegetable is called a {tokenizer.mask_token} and I eat one of them every day.\"\n",
        "sentence2 = f\"My favourite type of fruit is called a {tokenizer.mask_token} and I eat one of them every day.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JYIN_kaSInU",
        "outputId": "311987f5-2f9c-4a68-e4b7-67b7e9a74b17"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "9      banana        0.114603    0.266236       0.230937      0.178440   \n",
            "4       mango        0.059991    0.139366       0.134456      0.249007   \n",
            "2         nut        0.052449    0.121846       0.120143      0.068018   \n",
            "1       fruit        0.034807    0.080861       0.085385      0.088250   \n",
            "0       peach        0.032701    0.075967       0.081112      0.077764   \n",
            "6       berry        0.032125    0.074630       0.079915      0.053912   \n",
            "3        plum        0.029800    0.069228       0.075029      0.067843   \n",
            "7       lemon        0.027329    0.063488       0.069837      0.058413   \n",
            "5  strawberry        0.024800    0.057614       0.064416      0.056728   \n",
            "8      cherry        0.021852    0.050765       0.057991      0.101623   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "9     0.670235        0.772681      0.046298   0.050724  Ability  \n",
            "4     1.786718        1.851963      0.046298   0.050724  Ability  \n",
            "2     0.558233        0.566147      0.046298   0.050724  Ability  \n",
            "1     1.091377        1.033549      0.046298   0.050724  Ability  \n",
            "0     1.023651        0.958731      0.046298   0.050724  Ability  \n",
            "6     0.722390        0.674612      0.046298   0.050724  Ability  \n",
            "3     0.980001        0.904225      0.046298   0.050724  Ability  \n",
            "7     0.920065        0.836411      0.046298   0.050724  Ability  \n",
            "5     0.984631        0.880652      0.046298   0.050724  Ability  \n",
            "8     2.001842        1.752389      0.046298   0.050724  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## States"
      ],
      "metadata": {
        "id": "enrzyInsNktx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My favourite state in the U.S. is {tokenizer.mask_token} and I try to visit once a year.\"\n",
        "sentence2 = f\"My favourite Western state in the U.S. is {tokenizer.mask_token} and I try to visit once a year.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVMy20U_NXTo",
        "outputId": "1a68bc4b-8adb-4ec0-cb57-90daddf2a233"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "6  california        0.108853    0.298702       0.253782      0.201740   \n",
            "9     arizona        0.067399    0.184951       0.171971      0.100027   \n",
            "1       texas        0.055019    0.150977       0.145925      0.076750   \n",
            "8    colorado        0.031841    0.087376       0.093829      0.078146   \n",
            "7      oregon        0.028873    0.079231       0.086702      0.085660   \n",
            "5    oklahoma        0.019698    0.054052       0.063678      0.066355   \n",
            "3      nevada        0.016581    0.045499       0.055441      0.101803   \n",
            "4     montana        0.015908    0.043653       0.053601      0.142662   \n",
            "2       idaho        0.010460    0.028704       0.038248      0.049947   \n",
            "0     wyoming        0.009787    0.026856       0.036224      0.096909   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "6     0.675390        0.794937      0.051792   0.063822  Ability  \n",
            "9     0.540833        0.581653      0.051792   0.063822  Ability  \n",
            "1     0.508360        0.525959      0.051792   0.063822  Ability  \n",
            "8     0.894368        0.832858      0.051792   0.063822  Ability  \n",
            "7     1.081137        0.987980      0.051792   0.063822  Ability  \n",
            "5     1.227612        1.042041      0.051792   0.063822  Ability  \n",
            "3     2.237464        1.836232      0.051792   0.063822  Ability  \n",
            "4     3.268112        2.661544      0.051792   0.063822  Ability  \n",
            "2     1.740053        1.305857      0.051792   0.063822  Ability  \n",
            "0     3.608484        2.675286      0.051792   0.063822  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fear"
      ],
      "metadata": {
        "id": "TQ3uJs_hAU8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"The disease I fear most is {tokenizer.mask_token} and my uncle got it.\"\n",
        "sentence2 = f\"The infectious disease I fear most is {tokenizer.mask_token} and my uncle got it.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "ailDfiR8AV2Z",
        "outputId": "bda16792-8fc5-4655-8332-847e00396712",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "5      cancer        0.229240    0.470493       0.402558      0.077017   \n",
            "4     malaria        0.106886    0.219375       0.211679      0.148383   \n",
            "3        aids        0.053682    0.110178       0.119139      0.166081   \n",
            "9         hiv        0.032544    0.066793       0.078570      0.398082   \n",
            "7         flu        0.014566    0.029896       0.040419      0.026580   \n",
            "8   pneumonia        0.014291    0.029332       0.039776      0.025889   \n",
            "1    smallpox        0.013489    0.027684       0.037899      0.029321   \n",
            "6  infectious        0.010419    0.021383       0.030613      0.047714   \n",
            "2       virus        0.006332    0.012996       0.020290      0.034824   \n",
            "0       viral        0.005783    0.011870       0.018828      0.046109   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "5     0.163693        0.191318      0.146963   0.165864  Ability  \n",
            "4     0.676389        0.700978      0.146963   0.165864  Ability  \n",
            "3     1.507388        1.394003      0.146963   0.165864  Ability  \n",
            "9     5.959907        5.066617      0.146963   0.165864  Ability  \n",
            "7     0.889102        0.657616      0.146963   0.165864  Ability  \n",
            "8     0.882626        0.650858      0.146963   0.165864  Ability  \n",
            "1     1.059120        0.773652      0.146963   0.165864  Ability  \n",
            "6     2.231412        1.558639      0.146963   0.165864  Ability  \n",
            "2     2.679559        1.716315      0.146963   0.165864  Ability  \n",
            "0     3.884589        2.448967      0.146963   0.165864  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Countries"
      ],
      "metadata": {
        "id": "aNtCFUAWNra6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My favourite drink is {tokenizer.mask_token} and it tastes great.\"\n",
        "sentence2 = f\"My favourite alcoholic drink is {tokenizer.mask_token} and it tastes great.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3ZDa9S1NttO",
        "outputId": "e73176b6-77e1-4d46-af03-29bd0a93bda6"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "6      water        0.087032    0.196648       0.179372      0.148692   \n",
            "8     coffee        0.079112    0.178752       0.165583      0.075745   \n",
            "7        gin        0.061759    0.139543       0.134460      0.169855   \n",
            "1       wine        0.048430    0.109426       0.109678      0.080789   \n",
            "5        rum        0.034824    0.078685       0.083216      0.134153   \n",
            "2       beer        0.034671    0.078338       0.082906      0.072892   \n",
            "4  champagne        0.032639    0.073749       0.078821      0.045811   \n",
            "9      vodka        0.028924    0.065353       0.071264      0.144282   \n",
            "0       cola        0.019985    0.045155       0.052329      0.051135   \n",
            "3    bourbon        0.015203    0.034351       0.041662      0.076646   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "6     0.756133        0.828958      0.046304   0.051566  Ability  \n",
            "8     0.423745        0.457448      0.046304   0.051566  Ability  \n",
            "7     1.217224        1.263237      0.046304   0.051566  Ability  \n",
            "1     0.738293        0.736600      0.046304   0.051566  Ability  \n",
            "5     1.704928        1.612109      0.046304   0.051566  Ability  \n",
            "2     0.930489        0.879215      0.046304   0.051566  Ability  \n",
            "4     0.621178        0.581202      0.046304   0.051566  Ability  \n",
            "9     2.207720        2.024620      0.046304   0.051566  Ability  \n",
            "0     1.132432        0.977184      0.046304   0.051566  Ability  \n",
            "3     2.231272        1.839711      0.046304   0.051566  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pets"
      ],
      "metadata": {
        "id": "HvdEfNEeV8Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My favorite type of pet or farm animal is a {tokenizer.mask_token}, and it is very loyal.\"\n",
        "sentence2 = f\"My favorite type of pet is a {tokenizer.mask_token}, and it is very loyal.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2GlcJd1Wu_g",
        "outputId": "9d471e61-871c-472e-caad-5ecaf2894a75"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "9        dog        0.111114    0.227469       0.205238      0.170574   \n",
            "2        cat        0.071628    0.146635       0.141145      0.270100   \n",
            "5       wolf        0.061467    0.125834       0.123862      0.082584   \n",
            "6       bear        0.057627    0.117972       0.117255      0.115044   \n",
            "8       lion        0.044970    0.092062       0.094938      0.127784   \n",
            "3      tiger        0.040343    0.082590       0.086611      0.041469   \n",
            "0     rabbit        0.039527    0.080919       0.085133      0.051705   \n",
            "7  chihuahua        0.033485    0.068549       0.073927      0.033833   \n",
            "4    leopard        0.017254    0.035322       0.042148      0.068246   \n",
            "1      mouse        0.011063    0.022648       0.028927      0.038661   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "9     0.749878        0.831106      0.051144   0.051697  Ability  \n",
            "2     1.841989        1.913636      0.051144   0.051697  Ability  \n",
            "5     0.656294        0.666742      0.051144   0.051697  Ability  \n",
            "6     0.975183        0.981147      0.051144   0.051697  Ability  \n",
            "8     1.388024        1.345973      0.051144   0.051697  Ability  \n",
            "3     0.502112        0.478796      0.051144   0.051697  Ability  \n",
            "0     0.638977        0.607345      0.051144   0.051697  Ability  \n",
            "7     0.493551        0.457647      0.051144   0.051697  Ability  \n",
            "4     1.932106        1.619213      0.051144   0.051697  Ability  \n",
            "1     1.706991        1.336491      0.051144   0.051697  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Furniture"
      ],
      "metadata": {
        "id": "KoGPihHFXNx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"I need to buy a new piece of furniture or appliance called a {tokenizer.mask_token} for my house.\"\n",
        "sentence2 = f\"I need to buy a new piece of furniture called a {tokenizer.mask_token} for my house.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bASNdgtsWxDn",
        "outputId": "8a76c741-a3dc-4716-9249-7adba07eacfe"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "2      piano        0.012473    0.219646       0.167629      0.098736   \n",
            "1       room        0.007054    0.124207       0.117120      0.127745   \n",
            "5  furniture        0.006571    0.115705       0.111852      0.121403   \n",
            "9      chair        0.005992    0.105506       0.105533      0.114693   \n",
            "4    bedroom        0.005213    0.091797       0.096674      0.085581   \n",
            "3        bed        0.004793    0.084400       0.091601      0.106573   \n",
            "8       sofa        0.004417    0.077779       0.087060      0.103240   \n",
            "7      table        0.004067    0.071618       0.082654      0.088269   \n",
            "6       desk        0.003359    0.059155       0.073166      0.071658   \n",
            "0    dresser        0.002850    0.050187       0.065851      0.082102   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "2     0.449523        0.589015      0.024375   0.041689  Ability  \n",
            "1     1.028484        1.090718      0.024375   0.041689  Ability  \n",
            "5     1.049243        1.085386      0.024375   0.041689  Ability  \n",
            "9     1.087075        1.086797      0.024375   0.041689  Ability  \n",
            "4     0.932283        0.885253      0.024375   0.041689  Ability  \n",
            "3     1.262715        1.163456      0.024375   0.041689  Ability  \n",
            "8     1.327352        1.185859      0.024375   0.041689  Ability  \n",
            "7     1.232504        1.067935      0.024375   0.041689  Ability  \n",
            "6     1.211344        0.979390      0.024375   0.041689  Ability  \n",
            "0     1.635945        1.246784      0.024375   0.041689  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classics"
      ],
      "metadata": {
        "id": "OzL4VPWnXT_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"They are studying modern or classical {tokenizer.mask_token} at the university.\"\n",
        "sentence2 = f\"They are studying classical {tokenizer.mask_token} at the university.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5zGAiuaW6MO",
        "outputId": "1937a6e9-f44c-4de8-a038-f52c866ec55e"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "8        music        0.443805    0.573795       0.536867      0.500643   \n",
            "0    languages        0.146693    0.189659       0.192006      0.100392   \n",
            "3   literature        0.055413    0.071643       0.078533      0.075768   \n",
            "7      history        0.049378    0.063840       0.070655      0.026200   \n",
            "4        dance        0.041666    0.053870       0.060504      0.046529   \n",
            "5      studies        0.011827    0.015291       0.019256      0.031336   \n",
            "9  composition        0.010515    0.013594       0.017311      0.018114   \n",
            "6        greek        0.005779    0.007472       0.010073      0.023592   \n",
            "1    philology        0.005066    0.006550       0.008941      0.150025   \n",
            "2       ballet        0.003314    0.004285       0.006095      0.027400   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "8     0.872513        0.932528      0.057072   0.060386  Ability  \n",
            "0     0.529329        0.522860      0.057072   0.060386  Ability  \n",
            "3     1.057582        0.964792      0.057072   0.060386  Ability  \n",
            "7     0.410404        0.370823      0.057072   0.060386  Ability  \n",
            "4     0.863729        0.769035      0.057072   0.060386  Ability  \n",
            "5     2.049256        1.627378      0.057072   0.060386  Ability  \n",
            "9     1.332457        1.046409      0.057072   0.060386  Ability  \n",
            "6     3.157258        2.342124      0.057072   0.060386  Ability  \n",
            "1    22.905527       16.779814      0.057072   0.060386  Ability  \n",
            "2     6.394469        4.495711      0.057072   0.060386  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Big cats"
      ],
      "metadata": {
        "id": "lqHrV35KXWar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My favorite animal at the zoo is the {tokenizer.mask_token}, and I always visit its enclosure.\"\n",
        "sentence2 = f\"My favorite big cat at the zoo is the {tokenizer.mask_token}, and I always visit its enclosure.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR17BZ74XDKm",
        "outputId": "c6dfd6ac-6dca-475d-ae4f-2aa7ca15dfe9"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "6     lion        0.219672    0.546050       0.450130      0.204367   \n",
            "3    tiger        0.060831    0.151210       0.161040      0.201513   \n",
            "5     bear        0.029336    0.072922       0.090420      0.080488   \n",
            "4  leopard        0.027689    0.068827       0.086420      0.075231   \n",
            "2  panther        0.025657    0.063777       0.081401      0.088980   \n",
            "1      cat        0.025206    0.062657       0.080257      0.294430   \n",
            "0    mouse        0.013903    0.034558       0.050270      0.054991   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "6     0.374264        0.454018      0.124333   0.157728  Ability  \n",
            "3     1.332673        1.251321      0.124333   0.157728  Ability  \n",
            "5     1.103761        0.890162      0.124333   0.157728  Ability  \n",
            "4     1.093049        0.870529      0.124333   0.157728  Ability  \n",
            "2     1.395177        1.093105      0.124333   0.157728  Ability  \n",
            "1     4.699074        3.668591      0.124333   0.157728  Ability  \n",
            "0     1.591258        1.093917      0.124333   0.157728  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Around"
      ],
      "metadata": {
        "id": "DXrf5KcCXeWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My preferred mode of transportation is the {tokenizer.mask_token}, it's very convenient.\"\n",
        "sentence2 = f\"My preferred public transportation is the {tokenizer.mask_token}, it's very convenient.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqQZmF_uXgrT",
        "outputId": "60f4c493-66d7-4b3d-f1b8-4bcd93c0e009"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "0      car        0.167282    0.293049       0.265111      0.186921   \n",
            "4      bus        0.126271    0.221204       0.207027      0.195267   \n",
            "6     road        0.057955    0.101527       0.104744      0.046570   \n",
            "5   subway        0.049472    0.086666       0.091235      0.210164   \n",
            "2  airport        0.046693    0.081799       0.086772      0.089627   \n",
            "3  highway        0.044981    0.078798       0.084019      0.054571   \n",
            "7    train        0.033542    0.058760       0.065048      0.050261   \n",
            "1    buses        0.019355    0.033907       0.040364      0.073449   \n",
            "8  freeway        0.018005    0.031542       0.037895      0.046425   \n",
            "9    metro        0.007277    0.012748       0.017286      0.046745   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "0     0.637848        0.705065      0.051875   0.058197  Ability  \n",
            "4     0.882744        0.943193      0.051875   0.058197  Ability  \n",
            "6     0.458697        0.444610      0.051875   0.058197  Ability  \n",
            "5     2.424987        2.303559      0.051875   0.058197  Ability  \n",
            "2     1.095710        1.032914      0.051875   0.058197  Ability  \n",
            "3     0.692536        0.649503      0.051875   0.058197  Ability  \n",
            "7     0.855363        0.772679      0.051875   0.058197  Ability  \n",
            "1     2.166226        1.819669      0.051875   0.058197  Ability  \n",
            "8     1.471831        1.225108      0.051875   0.058197  Ability  \n",
            "9     3.666779        2.704198      0.051875   0.058197  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Holidays"
      ],
      "metadata": {
        "id": "Yu48jL0-Xs9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My favorite holiday is {tokenizer.mask_token}, and I always celebrate it with family.\"\n",
        "sentence2 = f\"My favorite winter holiday is {tokenizer.mask_token}, and I always celebrate it with family.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnhNAxUfXvGN",
        "outputId": "7c595007-e520-4b00-c16d-e27334c17e8c"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "7     christmas        0.803094    0.854978       0.840019      0.545480   \n",
            "1  thanksgiving        0.086861    0.092472       0.096960      0.132594   \n",
            "8     halloween        0.021869    0.023282       0.025901      0.030875   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "7     0.638004        0.649366      0.099916    0.10473  Ability  \n",
            "1     1.433873        1.367515      0.099916    0.10473  Ability  \n",
            "8     1.326135        1.192054      0.099916    0.10473  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cars"
      ],
      "metadata": {
        "id": "e4aLHglSX6Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"The best car brand, in my opinion, is {tokenizer.mask_token}.\"\n",
        "sentence2 = f\"The best U.K. car brand, in my opinion, is {tokenizer.mask_token}.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z3bimqxYm-j",
        "outputId": "e71e6e07-4475-4e13-b3bf-adf5af1ce4ab"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "0        bmw        0.084127    0.262735       0.222341      0.316667   \n",
            "7   mercedes        0.052325    0.163417       0.152603      0.077488   \n",
            "4       ford        0.047231    0.147506       0.140682      0.126972   \n",
            "2      honda        0.025577    0.079878       0.086626      0.058192   \n",
            "1  chevrolet        0.025214    0.078744       0.085659      0.077411   \n",
            "5    ferrari        0.025131    0.078486       0.085438      0.056851   \n",
            "3     toyota        0.024701    0.077145       0.084294      0.069140   \n",
            "9    renault        0.014676    0.045834       0.055937      0.081330   \n",
            "8     jaguar        0.014036    0.043835       0.053965      0.082484   \n",
            "6      china        0.007179    0.022420       0.031790      0.053466   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE Winner  \n",
            "0     1.205270        1.424240      0.043103   0.039289   Luce  \n",
            "7     0.474172        0.507773      0.043103   0.039289   Luce  \n",
            "4     0.860793        0.902545      0.043103   0.039289   Luce  \n",
            "2     0.728507        0.671758      0.043103   0.039289   Luce  \n",
            "1     0.983067        0.903713      0.043103   0.039289   Luce  \n",
            "5     0.724344        0.665402      0.043103   0.039289   Luce  \n",
            "3     0.896234        0.820220      0.043103   0.039289   Luce  \n",
            "9     1.774468        1.453957      0.043103   0.039289   Luce  \n",
            "8     1.881684        1.528478      0.043103   0.039289   Luce  \n",
            "6     2.384713        1.681845      0.043103   0.039289   Luce  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sports"
      ],
      "metadata": {
        "id": "k8ksRcXdBQhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"The sport that draws the biggest crowds is {tokenizer.mask_token}.\"\n",
        "sentence2 = f\"The winter sport that draws the biggest crowds is {tokenizer.mask_token}.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "6mCbKAn3BRsN",
        "outputId": "2f4ed569-3ad3-4db6-bb8e-96d94d228e09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "1    football        0.384491    0.563573       0.516096      0.453847   \n",
            "3  basketball        0.174353    0.255560       0.253395      0.092775   \n",
            "6    swimming        0.031364    0.045972       0.055432      0.050431   \n",
            "7     cycling        0.028256    0.041417       0.050581      0.058380   \n",
            "5   athletics        0.023070    0.033816       0.042327      0.028875   \n",
            "4   wrestling        0.016009    0.023465       0.030717      0.033665   \n",
            "0      rowing        0.012924    0.018943       0.025467      0.027891   \n",
            "9      hockey        0.008869    0.013001       0.018328      0.050509   \n",
            "2      skiing        0.001838    0.002694       0.004636      0.157429   \n",
            "8     skating        0.001064    0.001559       0.002877      0.046197   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "1     0.805304        0.879385      0.074975   0.081484  Ability  \n",
            "3     0.363027        0.366128      0.074975   0.081484  Ability  \n",
            "6     1.097000        0.909782      0.074975   0.081484  Ability  \n",
            "7     1.409567        1.154194      0.074975   0.081484  Ability  \n",
            "5     0.853886        0.682189      0.074975   0.081484  Ability  \n",
            "4     1.434706        1.095992      0.074975   0.081484  Ability  \n",
            "0     1.472335        1.095173      0.074975   0.081484  Ability  \n",
            "9     3.885142        2.755900      0.074975   0.081484  Ability  \n",
            "2    58.441515       33.954800      0.074975   0.081484  Ability  \n",
            "8    29.629459       16.058919      0.074975   0.081484  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Programming languages"
      ],
      "metadata": {
        "id": "ipPL-8uTY_RP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My favorite programming language is {tokenizer.mask_token}, I write code with it daily.\"\n",
        "sentence2 = f\"My favorite object-oriented programming language is {tokenizer.mask_token}, I write code with it daily.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)\n",
        "variations = ['functional','object-oriented','procedural','classic']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylVmW2qgYyxV",
        "outputId": "1e86795a-2976-428b-9eb9-af8897a1f836"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "8        c        0.393775    0.519164       0.490528      0.264072   \n",
            "6     java        0.213168    0.281047       0.277894      0.453514   \n",
            "1   python        0.082175    0.108342       0.115880      0.133333   \n",
            "3   pascal        0.025111    0.033108       0.039455      0.093922   \n",
            "0      php        0.018903    0.024923       0.030531      0.018649   \n",
            "5    basic        0.011095    0.014628       0.018872      0.007091   \n",
            "9     ruby        0.007781    0.010259       0.013712      0.015548   \n",
            "4  algebra        0.002346    0.003093       0.004672      0.003665   \n",
            "7    swift        0.002103    0.002773       0.004236      0.004351   \n",
            "2      sql        0.002020    0.002663       0.004086      0.005856   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "8     0.508649        0.538343      0.092565   0.099638  Ability  \n",
            "6     1.613657        1.631967      0.092565   0.099638  Ability  \n",
            "1     1.230665        1.150611      0.092565   0.099638  Ability  \n",
            "3     2.836864        2.380513      0.092565   0.099638  Ability  \n",
            "0     0.748263        0.610808      0.092565   0.099638  Ability  \n",
            "5     0.484780        0.375754      0.092565   0.099638  Ability  \n",
            "9     1.515582        1.133865      0.092565   0.099638  Ability  \n",
            "4     1.184646        0.784300      0.092565   0.099638  Ability  \n",
            "7     1.569128        1.027185      0.092565   0.099638  Ability  \n",
            "2     2.198874        1.433044      0.092565   0.099638  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Starting the day?"
      ],
      "metadata": {
        "id": "njHD9X2wY4Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"I like to drink {tokenizer.mask_token} in the morning to start my day.\"\n",
        "sentence2 = f\"I like to drink hot {tokenizer.mask_token} in the morning to start my day.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb7oM4tcY26Z",
        "outputId": "88f91425-97df-47f8-e4fa-958680cf0b3d"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "3  coffee        0.157122    0.549390       0.457351      0.238140   \n",
            "2   water        0.065113    0.227673       0.237397      0.657931   \n",
            "1    beer        0.045442    0.158892       0.182155      0.008129   \n",
            "4     tea        0.008099    0.028318       0.051477      0.059600   \n",
            "5    milk        0.007799    0.027269       0.050102      0.006568   \n",
            "0  drinks        0.002419    0.008458       0.021308      0.029632   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "3     0.433463        0.520695       0.20705   0.226047  Ability  \n",
            "2     2.889812        2.771433       0.20705   0.226047  Ability  \n",
            "1     0.051160        0.044627       0.20705   0.226047  Ability  \n",
            "4     2.104672        1.157794       0.20705   0.226047  Ability  \n",
            "5     0.240859        0.131094       0.20705   0.226047  Ability  \n",
            "0     3.503310        1.390604       0.20705   0.226047  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scientists"
      ],
      "metadata": {
        "id": "k_soG6r5ZIht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My favorite scientist's last name is {tokenizer.mask_token}, they changed the world.\"\n",
        "sentence2 = f\"My favorite 19th Century scientist's last name is {tokenizer.mask_token}, they changed the world.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZo4xOM9ZH1V",
        "outputId": "76ee51dd-60b4-4d00-b36c-65beab23269c"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "1  einstein        0.022025    0.330548       0.235863      0.106760   \n",
            "8     james        0.012042    0.180729       0.161632      0.166290   \n",
            "4     peter        0.010730    0.161033       0.150376      0.116121   \n",
            "6   charles        0.005971    0.089615       0.104032      0.106001   \n",
            "5    darwin        0.004373    0.065634       0.085521      0.200846   \n",
            "7  franklin        0.003387    0.050827       0.072766      0.070512   \n",
            "0    joseph        0.002859    0.042905       0.065460      0.072710   \n",
            "2     henry        0.002689    0.040351       0.062895      0.092065   \n",
            "3    thomas        0.002556    0.038358       0.060893      0.068695   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "1     0.322979        0.452635      0.059755   0.091729  Ability  \n",
            "8     0.920105        1.028815      0.059755   0.091729  Ability  \n",
            "4     0.721101        0.772205      0.059755   0.091729  Ability  \n",
            "6     1.182846        1.018923      0.059755   0.091729  Ability  \n",
            "5     3.060084        2.348504      0.059755   0.091729  Ability  \n",
            "7     1.387287        0.969017      0.059755   0.091729  Ability  \n",
            "0     1.694687        1.110749      0.059755   0.091729  Ability  \n",
            "2     2.281618        1.463793      0.059755   0.091729  Ability  \n",
            "3     1.790904        1.128132      0.059755   0.091729  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More pets"
      ],
      "metadata": {
        "id": "OUVTnWekZTI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My preferred pet is a {tokenizer.mask_token}, they make great companions.\"\n",
        "sentence2 = f\"My preferred small pet is a {tokenizer.mask_token}, they make great companions.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9PmEd2SX82L",
        "outputId": "77a5f4b6-f00d-4d0b-9233-866f04e46a3a"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "2       cat        0.075033    0.155339       0.147005      0.160443   \n",
            "5      bear        0.068126    0.141039       0.135448      0.127901   \n",
            "8      lion        0.062841    0.130099       0.126393      0.090659   \n",
            "0      deer        0.061382    0.127077       0.123891      0.132946   \n",
            "6      wolf        0.055966    0.115865       0.114572      0.095933   \n",
            "3     tiger        0.050032    0.103580       0.104115      0.087945   \n",
            "9       dog        0.043436    0.089925       0.092329      0.094879   \n",
            "4  squirrel        0.029307    0.060674       0.066128      0.082661   \n",
            "1     mouse        0.018558    0.038420       0.044893      0.068674   \n",
            "7    parrot        0.018347    0.037983       0.044457      0.057961   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "2     1.032855        1.091412      0.017981   0.020622  Ability  \n",
            "5     0.906848        0.944275      0.017981   0.020622  Ability  \n",
            "8     0.696849        0.717282      0.017981   0.020622  Ability  \n",
            "0     1.046185        1.073085      0.017981   0.020622  Ability  \n",
            "6     0.827969        0.837317      0.017981   0.020622  Ability  \n",
            "3     0.849057        0.844692      0.017981   0.020622  Ability  \n",
            "9     1.055091        1.027609      0.017981   0.020622  Ability  \n",
            "4     1.362362        1.250017      0.017981   0.020622  Ability  \n",
            "1     1.787468        1.529740      0.017981   0.020622  Ability  \n",
            "7     1.525957        1.303750      0.017981   0.020622  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My favorite baby name is {tokenizer.mask_token}, and I always associate it with family.\"\n",
        "sentence2 = f\"My favorite girl's baby name is {tokenizer.mask_token}, and I always associate it with family.\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcNJv4kGuZMh",
        "outputId": "8c1011b8-43e1-47d1-c2da-7886f21676e7"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "3      lily        0.015596    0.203468       0.161750      0.145201   \n",
            "5     emily        0.011547    0.150642       0.133103      0.162862   \n",
            "0       mia        0.008624    0.112507       0.110161      0.131783   \n",
            "4     bella        0.008521    0.111161       0.109334      0.088390   \n",
            "8     sarah        0.006815    0.088915       0.094442      0.094142   \n",
            "7    rachel        0.005872    0.076603       0.085626      0.071505   \n",
            "9      kate        0.005852    0.076348       0.085438      0.084366   \n",
            "1    lauren        0.004680    0.061055       0.073866      0.072298   \n",
            "6  brittany        0.004630    0.060399       0.073332      0.075525   \n",
            "2     chloe        0.004515    0.058902       0.072112      0.073929   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "3     0.713629        0.897683      0.015089   0.022656  Ability  \n",
            "5     1.081119        1.223580      0.015089   0.022656  Ability  \n",
            "0     1.171325        1.196278      0.015089   0.022656  Ability  \n",
            "4     0.795158        0.808441      0.015089   0.022656  Ability  \n",
            "8     1.058783        0.996824      0.015089   0.022656  Ability  \n",
            "7     0.933443        0.835082      0.015089   0.022656  Ability  \n",
            "9     1.105008        0.987451      0.015089   0.022656  Ability  \n",
            "1     1.184147        0.978775      0.015089   0.022656  Ability  \n",
            "6     1.250435        1.029908      0.015089   0.022656  Ability  \n",
            "2     1.255132        1.025196      0.015089   0.022656  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = f\"My favorite age is {tokenizer.mask_token}, and my daughter is that age\"\n",
        "sentence2 = f\"My favorite age for middle school kids is {tokenizer.mask_token}, and my daughter is that age\"\n",
        "df = luce_check(sentence1, sentence2)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_JRORWrvH1C",
        "outputId": "d0517845-251d-4582-ada5-702539624157"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Choice  Original score  Luce score  Ability score  Actual score  \\\n",
            "7   eight        0.045801    0.155288       0.142627      0.152468   \n",
            "9  twelve        0.040842    0.138472       0.130246      0.139279   \n",
            "4  eleven        0.037958    0.128694       0.123046      0.085072   \n",
            "0   seven        0.033578    0.113845       0.111671      0.085769   \n",
            "5    five        0.033333    0.113015       0.111032      0.084129   \n",
            "3      16        0.027800    0.094257       0.096288      0.103968   \n",
            "2     six        0.022533    0.076396       0.081655      0.089710   \n",
            "1      12        0.019562    0.066326       0.073144      0.116064   \n",
            "6       9        0.018803    0.063752       0.070882      0.068647   \n",
            "8      13        0.014734    0.049956       0.058531      0.074894   \n",
            "\n",
            "   Actual/Luce  Actual/Ability  Ability RMSE  Luce RMSE   Winner  \n",
            "7     0.981840        1.068999      0.022921   0.026316  Ability  \n",
            "9     1.005830        1.069359      0.022921   0.026316  Ability  \n",
            "4     0.661040        0.691383      0.022921   0.026316  Ability  \n",
            "0     0.753386        0.768054      0.022921   0.026316  Ability  \n",
            "5     0.744404        0.757698      0.022921   0.026316  Ability  \n",
            "3     1.103035        1.079763      0.022921   0.026316  Ability  \n",
            "2     1.174276        1.098638      0.022921   0.026316  Ability  \n",
            "1     1.749902        1.586790      0.022921   0.026316  Ability  \n",
            "6     1.076778        0.968457      0.022921   0.026316  Ability  \n",
            "8     1.499213        1.279559      0.022921   0.026316  Ability  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax\n",
        "\n",
        "Just for fun, we can do some brain surgery on the LLM to force it to obey Luce Choice Axiom."
      ],
      "metadata": {
        "id": "nFnlglhL_mnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import logging\n",
        "from transformers import logging as transformers_logging\n",
        "from transformers import pipeline\n",
        "transformers_logging.set_verbosity_error()\n",
        "\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def fill_in_missing_word(sentence, exclude_words=None, top_k=20):\n",
        "    # Tokenize the input sentence\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "    # Find the index of the masked token\n",
        "    mask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
        "\n",
        "    # Get the model's predictions (logits)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    if exclude_words:\n",
        "        # Get the IDs of the words to exclude\n",
        "        exclude_ids = tokenizer.convert_tokens_to_ids(exclude_words)\n",
        "        # Set their logits to a very low value\n",
        "        logits[0, mask_token_index, exclude_ids] = -float('inf')\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probs = torch.softmax(logits[0, mask_token_index], dim=-1).squeeze()\n",
        "\n",
        "    # Get the top_k predictions\n",
        "    top_k_probs, top_k_indices = torch.topk(probs, top_k, dim=-1)\n",
        "\n",
        "    top_k_tokens = tokenizer.convert_ids_to_tokens(top_k_indices.tolist())\n",
        "    top_k_probs = top_k_probs.tolist()\n",
        "\n",
        "    # Store the top predictions in a dictionary\n",
        "    predictions = dict(zip(top_k_tokens, top_k_probs))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Use the tokenizer's mask token in the sentence\n",
        "sentence = f\"The space-ship was so {tokenizer.mask_token} it was not possible to see what was behind it.\"\n",
        "\n",
        "# First iteration: get original probabilities\n",
        "original_predictions = fill_in_missing_word(sentence, top_k=20)\n",
        "\n",
        "# Extract the top predicted word and its probability\n",
        "first_word = max(original_predictions, key=original_predictions.get)\n",
        "first_prob = original_predictions[first_word]\n",
        "\n",
        "print(\"Original Top Predictions:\")\n",
        "for word, prob in original_predictions.items():\n",
        "    print(f\"{word}: {prob:.6f}\")\n",
        "\n",
        "print(f\"\\nFirst answer: '{first_word}', Probability: {first_prob:.6f}\\n\")\n",
        "\n",
        "# Second iteration: remove the most probable word\n",
        "new_predictions = fill_in_missing_word(sentence, exclude_words=[first_word], top_k=20)\n",
        "\n",
        "print(\"New Top Predictions After Excluding the First Word:\")\n",
        "for word, prob in new_predictions.items():\n",
        "    print(f\"{word}: {prob:.6f}\")\n",
        "\n",
        "# Compare probabilities according to Luce Choice Axiom\n",
        "print(\"\\nComparing Ratios According to Luce Choice Axiom:\\n\")\n",
        "\n",
        "# Calculate the sum of probabilities excluding the first word\n",
        "sum_original_probs_excl_first = sum(original_predictions[word] for word in original_predictions if word != first_word)\n",
        "sum_new_probs = sum(new_predictions.values())\n",
        "\n",
        "print(f\"Sum of original probabilities (excluding '{first_word}'): {sum_original_probs_excl_first:.6f}\")\n",
        "print(f\"Sum of new probabilities: {sum_new_probs:.6f}\")\n",
        "\n",
        "# Verify that sums are approximately equal (should be close to 1 - first_prob)\n",
        "print(f\"1 - Probability of '{first_word}': {1 - first_prob:.6f}\")\n",
        "\n",
        "# Check ratios for each word in new_predictions\n",
        "print(\"\\nWord\\tOriginal Prob\\tExpected New Prob\\tActual New Prob\\tRatio (Actual/Expected)\")\n",
        "for word in new_predictions:\n",
        "    original_prob = original_predictions.get(word, 0)\n",
        "    expected_new_prob = original_prob / (1 - first_prob)\n",
        "    actual_new_prob = new_predictions[word]\n",
        "    ratio = actual_new_prob / expected_new_prob if expected_new_prob != 0 else 0\n",
        "    print(f\"{word}\\t{original_prob:.6f}\\t{expected_new_prob:.6f}\\t{actual_new_prob:.6f}\\t{ratio:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e93c68-53a1-43b0-b952-9d5a1f7df847",
        "id": "seIeAVan_oNY"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Top Predictions:\n",
            "large: 0.344735\n",
            "small: 0.227211\n",
            "massive: 0.106483\n",
            "huge: 0.058782\n",
            "big: 0.030036\n",
            "close: 0.020969\n",
            "dark: 0.020564\n",
            "enormous: 0.017063\n",
            "low: 0.010211\n",
            "tiny: 0.010106\n",
            "heavy: 0.009116\n",
            "immense: 0.007942\n",
            "tall: 0.007581\n",
            "vast: 0.007423\n",
            "high: 0.006501\n",
            "narrow: 0.004375\n",
            "powerful: 0.003378\n",
            "quiet: 0.003095\n",
            "thin: 0.003060\n",
            "silent: 0.002666\n",
            "\n",
            "First answer: 'large', Probability: 0.344735\n",
            "\n",
            "New Top Predictions After Excluding the First Word:\n",
            "small: 0.346745\n",
            "massive: 0.162502\n",
            "huge: 0.089707\n",
            "big: 0.045837\n",
            "close: 0.032000\n",
            "dark: 0.031383\n",
            "enormous: 0.026040\n",
            "low: 0.015584\n",
            "tiny: 0.015423\n",
            "heavy: 0.013912\n",
            "immense: 0.012120\n",
            "tall: 0.011569\n",
            "vast: 0.011328\n",
            "high: 0.009920\n",
            "narrow: 0.006677\n",
            "powerful: 0.005156\n",
            "quiet: 0.004724\n",
            "thin: 0.004669\n",
            "silent: 0.004069\n",
            "black: 0.003872\n",
            "\n",
            "Comparing Ratios According to Luce Choice Axiom:\n",
            "\n",
            "Sum of original probabilities (excluding 'large'): 0.556562\n",
            "Sum of new probabilities: 0.853237\n",
            "1 - Probability of 'large': 0.655265\n",
            "\n",
            "Word\tOriginal Prob\tExpected New Prob\tActual New Prob\tRatio (Actual/Expected)\n",
            "small\t0.227211\t0.346747\t0.346745\t0.999994\n",
            "massive\t0.106483\t0.162503\t0.162502\t0.999994\n",
            "huge\t0.058782\t0.089707\t0.089707\t0.999994\n",
            "big\t0.030036\t0.045838\t0.045837\t0.999994\n",
            "close\t0.020969\t0.032000\t0.032000\t0.999994\n",
            "dark\t0.020564\t0.031383\t0.031383\t0.999994\n",
            "enormous\t0.017063\t0.026040\t0.026040\t0.999994\n",
            "low\t0.010211\t0.015584\t0.015584\t0.999994\n",
            "tiny\t0.010106\t0.015423\t0.015423\t0.999994\n",
            "heavy\t0.009116\t0.013912\t0.013912\t0.999994\n",
            "immense\t0.007942\t0.012120\t0.012120\t0.999994\n",
            "tall\t0.007581\t0.011569\t0.011569\t0.999994\n",
            "vast\t0.007423\t0.011328\t0.011328\t0.999994\n",
            "high\t0.006501\t0.009920\t0.009920\t0.999994\n",
            "narrow\t0.004375\t0.006677\t0.006677\t0.999994\n",
            "powerful\t0.003378\t0.005156\t0.005156\t0.999994\n",
            "quiet\t0.003095\t0.004724\t0.004724\t0.999994\n",
            "thin\t0.003060\t0.004669\t0.004669\t0.999994\n",
            "silent\t0.002666\t0.004069\t0.004069\t0.999994\n",
            "black\t0.000000\t0.000000\t0.003872\t0.000000\n"
          ]
        }
      ]
    }
  ]
}