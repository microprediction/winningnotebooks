{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+gkc33I/sKKj2xh/lB3ZT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microprediction/winningnotebooks/blob/main/LLM_Quinellas_Comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C_4E5p8fd80E",
        "outputId": "75b5416e-7ff2-46fe-e85a-7913d7201098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting winning\n",
            "  Downloading winning-1.0.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from winning) (1.26.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from winning) (7.4.4)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (from winning) (1.0.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from winning) (0.44.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.2)\n",
            "Downloading winning-1.0.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: winning\n",
            "Successfully installed winning-1.0.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install winning\n",
        "!pip install pandas\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Luce's Choice Axiom versus the Standard Normal Race model\n",
        "The methodology is as follows.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "82THYxZp-nI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A contest model for choice\n",
        "\n",
        "Luce is trivial. Let's just implement the second here using the `winning` package:;"
      ],
      "metadata": {
        "id": "0etgB1K41-jT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quinella pricing"
      ],
      "metadata": {
        "id": "BmW_yeMjam_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from winning.lattice_conventions import STD_L, STD_A\n",
        "from winning.lattice import skew_normal_density, densities_from_offsets, get_the_rest, _loser_of_two_pdf,\\\n",
        "    beats, winner_of_many, cdf_to_pdf\n",
        "from winning.lattice_calibration import state_price_implied_ability\n",
        "\n",
        "\n",
        "def compute_skew_normal_quinellas(p:[float], L=551, a=0):\n",
        "    \"\"\" Produce quinella table, and also return densities\n",
        "\n",
        "    :param p:  Vector of state prices\n",
        "    :param L:  500 by default, half that is probably fine\n",
        "    :return: quinellas, densities\n",
        "    \"\"\"\n",
        "\n",
        "    # Calibration\n",
        "    unit = 1.0\n",
        "    density = skew_normal_density(L=L, unit=unit, loc=0, scale=50.0, a=a)\n",
        "    offsets = state_price_implied_ability(prices=p, density=density)\n",
        "    densities = densities_from_offsets(density, offsets)\n",
        "    densityAll, multiplicityAll = winner_of_many(densities)\n",
        "\n",
        "    n = len(p)\n",
        "    quinellas = np.zeros(shape=(n, n))\n",
        "    for h0 in range(n):\n",
        "        density0 = densities[h0]\n",
        "        cdfRest0, multiplicityRest0 = get_the_rest(density=density0, densityAll=densityAll,\n",
        "                                                   multiplicityAll=multiplicityAll, cdf=None, cdfAll=None)\n",
        "        for h1 in range(n):\n",
        "            if h1 > h0:\n",
        "                density1 = densities[h1]\n",
        "                cdfRest01, multiplicityRest01 = get_the_rest(density=density1, densityAll=None,\n",
        "                                                             multiplicityAll=multiplicityRest0, cdf=None,\n",
        "                                                             cdfAll=cdfRest0)\n",
        "                pdfRest01 = cdf_to_pdf(cdfRest01)\n",
        "                loser01, loser_multiplicity01 = _loser_of_two_pdf(density0, density1)\n",
        "                quinellas[h0, h1] = beats(loser01, loser_multiplicity01, pdfRest01, multiplicityRest01)\n",
        "                quinellas[h1, h0] = quinellas[h0, h1]\n",
        "\n",
        "    return quinellas\n",
        "\n",
        "qins = compute_skew_normal_quinellas(p=[0.5,0.3,0.1,0.1,0.1,0.001,0.001,0.001,0.001,0.001,0.001])\n",
        "qins[:4,:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pVQBEnaDaofR",
        "outputId": "316d08fe-a5fc-4c0c-a54d-c4a610899c1e"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.33139024, 0.12176597, 0.12176597],\n",
              "       [0.33139024, 0.        , 0.06868425, 0.06868425],\n",
              "       [0.12176597, 0.06868425, 0.        , 0.02362145],\n",
              "       [0.12176597, 0.06868425, 0.02362145, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quinella pricing (Luce / Harville)"
      ],
      "metadata": {
        "id": "wiCsSZchT9u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_harville_quinellas(p):\n",
        "    \"\"\"\n",
        "    Compute Harville Quinellas (joint probabilities for unordered pairs) from individual probabilities assuming independence.\n",
        "\n",
        "    Args:\n",
        "        p (list of float): List of individual probabilities for each state/event. Should sum to <=1.\n",
        "\n",
        "    Returns:\n",
        "        list of lists: Matrix-like structure where the element at [i][j] is the joint probability P({i, j}),\n",
        "                       with diagonal elements being 1.0 to match the format requested.\n",
        "    \"\"\"\n",
        "    from itertools import combinations\n",
        "\n",
        "    n = len(p)\n",
        "    quinella_matrix = [[0.0] * n for _ in range(n)]\n",
        "\n",
        "    # Compute unnormalized joint probabilities\n",
        "    for i, j in combinations(range(n), 2):\n",
        "        if i != j:\n",
        "          joint_prob = p[i] * p[j]\n",
        "          quinella_matrix[i][j] = quinella_matrix[j][i] = joint_prob\n",
        "\n",
        "    # Normalize the joint probabilities so that their sum equals the total probability of any two events occurring\n",
        "    total_joint_prob = sum(sum(row) for row in quinella_matrix) / 2  # Divide by 2 to avoid double-counting pairs\n",
        "    if total_joint_prob > 0:\n",
        "        quinella_matrix = [\n",
        "            [cell / total_joint_prob if i != j else 0.0 for j, cell in enumerate(row)]\n",
        "            for i, row in enumerate(quinella_matrix)\n",
        "        ]\n",
        "\n",
        "    return quinella_matrix\n",
        "\n",
        "# Example usage\n",
        "result = compute_harville_quinellas(p=[0.5, 0.3, 0.2])\n",
        "for row in result:\n",
        "    print(row)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU6nA1MOT8ua",
        "outputId": "cbae48a4-1f3f-438c-e859-d2d693d19b00"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.48387096774193544, 0.32258064516129037]\n",
            "[0.48387096774193544, 0.0, 0.1935483870967742]\n",
            "[0.32258064516129037, 0.1935483870967742, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers numpy pandas scipy"
      ],
      "metadata": {
        "id": "ODgmK7QPcHQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "dea39da9-ba43-4bde-b8c7-27ebbf84e5e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Missing word utility"
      ],
      "metadata": {
        "id": "JyocXz9mex_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_quinellas(prompt_pair, top_k=10):\n",
        "    \"\"\"\n",
        "    Receives a prompt pair like the following:\n",
        "      - \"I visited the state called [MASK] last year and it is one of my favorite states in the U.S.A.\"\n",
        "      - \"I visited two states called [ANSWER] and [MASK] last year and they are my two favorite states in the U.S.A.\"\n",
        "\n",
        "    First, it will ask an LLM to fill in the missing token and extract the token probabilities.\n",
        "    We will take the top 10 and create a list called 'names' (lowercase) and one called 'p' where the latter holds\n",
        "    renormalized probabilities adding to unity.\n",
        "\n",
        "    Second, for each i, name in enumerate(names), we will substitute into the second prompt.\n",
        "    So if the name is 'arizona', we get something like:\n",
        "      - \"I visited two states called arizona and [MASK] last year and they are my two favorite states in the U.S.A.\"\n",
        "\n",
        "    Eliminate any responses that are not in the set NAMES / {name}.\n",
        "    Renormalize the token probabilities.\n",
        "\n",
        "    This gives a way of assigning 'exacta' probabilities ex[i, :] where diagonals are zero.\n",
        "    When we have done this for all names, we also add ex to its own transpose to get qu[:, :].\n",
        "\n",
        "    Return this quinella probability table.\n",
        "    \"\"\"\n",
        "    from transformers import pipeline\n",
        "    import numpy as np\n",
        "\n",
        "    # Initialize the fill-mask pipeline with a model that supports mask filling\n",
        "    fill_mask = pipeline('fill-mask', model='roberta-base')\n",
        "\n",
        "    # Unpack the prompt pair\n",
        "    prompt_single, prompt_double = prompt_pair\n",
        "\n",
        "    # Adjust the mask tokens for the model\n",
        "    mask_token = fill_mask.tokenizer.mask_token  # This will be '<mask>' for roberta-base\n",
        "\n",
        "    # Step 1: Get top 10 names and their probabilities from the first prompt\n",
        "    prompt_single = prompt_single.replace('[MASK]', mask_token)\n",
        "\n",
        "    # Get predictions\n",
        "    results = fill_mask(prompt_single, top_k=top_k)\n",
        "\n",
        "    # Extract tokens and their probabilities\n",
        "    names = []\n",
        "    probs = []\n",
        "    for res in results:\n",
        "        token_str = res['token_str'].strip().lower()\n",
        "        names.append(token_str)\n",
        "        probs.append(res['score'])\n",
        "\n",
        "    # Normalize probabilities to sum to 1\n",
        "    total_prob = sum(probs)\n",
        "    p = [prob / total_prob for prob in probs]\n",
        "\n",
        "    # Initialize the exacta probability matrix\n",
        "    n = len(names)\n",
        "    ex = np.zeros((n, n))\n",
        "\n",
        "    # Step 2: For each name, get probabilities for the second [MASK]\n",
        "    for i, name in enumerate(names):\n",
        "        # Substitute the name into the second prompt\n",
        "        prompt = prompt_double.replace('[ANSWER]', name)\n",
        "        prompt = prompt.replace('[MASK]', mask_token)\n",
        "\n",
        "        # Get predictions\n",
        "        results = fill_mask(prompt, top_k=50)  # Increase top_k to ensure coverage\n",
        "\n",
        "        # Extract tokens and their probabilities\n",
        "        other_names = []\n",
        "        probs_others = []\n",
        "        for res in results:\n",
        "            token_str = res['token_str'].strip().lower()\n",
        "            other_names.append(token_str)\n",
        "            probs_others.append(res['score'])\n",
        "\n",
        "        # Filter out the current name and names not in the list\n",
        "        allowed_names = set(names) - {name}\n",
        "        filtered_probs = {}\n",
        "        for other_name, prob in zip(other_names, probs_others):\n",
        "            if other_name in allowed_names:\n",
        "                filtered_probs[other_name] = prob\n",
        "\n",
        "        # Renormalize probabilities\n",
        "        total_prob = sum(filtered_probs.values())\n",
        "        if total_prob > 0:\n",
        "            filtered_probs = {k: v / total_prob for k, v in filtered_probs.items()}\n",
        "        else:\n",
        "            # If no allowed names are found, skip this iteration\n",
        "            continue\n",
        "\n",
        "        # Map other_name to index j\n",
        "        name_to_index = {n: idx for idx, n in enumerate(names)}\n",
        "        # Fill the exacta matrix\n",
        "        for other_name, prob in filtered_probs.items():\n",
        "            j = name_to_index[other_name]\n",
        "            ex[i, j] = p[i]*prob\n",
        "\n",
        "    # Zero out the diagonal\n",
        "    np.fill_diagonal(ex, 0)\n",
        "\n",
        "    # Compute the quinella probability table\n",
        "    qu = ex + ex.T\n",
        "\n",
        "\n",
        "    return p, qu, names\n",
        "\n",
        "\n",
        "def quinella_comparison(prompt_pair, top_k=10):\n",
        "    # Get LLM, normal model and harville implied quinellas\n",
        "    # Compute several measures of discrepancy between LLM and estimated probabilities\n",
        "    p, qu_llm, names = llm_quinellas(prompt_pair=prompt_pair,top_k=top_k)\n",
        "    qu_normal = compute_skew_normal_quinellas(p)\n",
        "    qu_harville = compute_harville_quinellas(p)\n",
        "    srt = sorted(list(zip(p,names)), reverse=True)\n",
        "    print({'probs':srt})\n",
        "\n",
        "    # Compute RMSE between qu_llm and qu_normal\n",
        "    rmse_normal = np.sqrt(np.mean((qu_llm - qu_normal) ** 2))\n",
        "\n",
        "    # Compute RMSE between qu_llm and qu_harville\n",
        "    rmse_harville = np.sqrt(np.mean((qu_llm - qu_harville) ** 2))\n",
        "\n",
        "    # Compute RMSE between qu_llm and qu_harville\n",
        "    rmse_diff = np.sqrt(np.mean((qu_harville - qu_normal) ** 2))\n",
        "\n",
        "\n",
        "    # Print the RMSE values\n",
        "    print(f\"RMSE between LLM quinellas and Skew Normal quinellas: {rmse_normal:.6f}\")\n",
        "    print(f\"RMSE between LLM quinellas and Harville quinellas: {rmse_harville:.6f}\")\n",
        "    print(f\"RMSE between Skew and Harville quinellas: {rmse_diff:.6f}\")\n",
        "    if rmse_normal < rmse_harville:\n",
        "        better_model = \"Skew Normal\"\n",
        "    else:\n",
        "        better_model = \"Harville\"\n",
        "\n",
        "    print(f\"The {better_model} model better predicts the actual quinella probabilities.\")\n",
        "    return rmse_harville, rmse_normal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prompt_pair = (\n",
        "    \"I visited the state called [MASK] last year and it is one of my favorite states in the U.S.A.\",\n",
        "    \"I visited two states called [ANSWER] and [MASK] last year and they are my two favorite states in the U.S.A.\"\n",
        ")\n",
        "quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT3wZqK3Ur7Z",
        "outputId": "6d8df003-eb59-40cd-bc41-73aa54533d42"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.19252209207465457, 'arizona'), (0.11820234007751466, 'texas'), (0.10717900748068498, 'oregon'), (0.10114625244209448, 'indiana'), (0.10052167784050628, 'florida'), (0.0904307397306346, 'california'), (0.08755574201564277, 'georgia'), (0.06912437443572696, 'wisconsin'), (0.06699298122438921, 'arkansas'), (0.0663247926781515, 'utah')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.016568\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.016598\n",
            "RMSE between Skew and Harville quinellas: 0.000664\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.016598399026136686, 0.016568333671103393)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I visited the country called [MASK] last year and it is one of my favorite countries in REGION\",\n",
        "    \"I visited two countries called [ANSWER] and [MASK] last year and they are my two favorite countries in REGION\"\n",
        ")\n",
        "for region in ['Asia','Europe','the Americas','Africa','the Southern Hemisphere','the World']:\n",
        "     prompt_pair = [ pp.replace('REGION',region) for pp in prompt_pair_template]\n",
        "     quinella_comparison(prompt_pair=prompt_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8CpuilSkj7d",
        "outputId": "ac9d9283-7ea3-46a8-e923-81ccd83e9b2b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.1737887911458916, 'vietnam'), (0.16538282901836396, 'myanmar'), (0.1207179720561625, 'cambodia'), (0.11862311323457679, 'burma'), (0.09436936278318456, 'bangladesh'), (0.0715250775055774, 'thailand'), (0.06873332038425296, 'pakistan'), (0.06643431411960922, 'singapore'), (0.06336770805747138, 'india'), (0.05705751169490962, 'nepal')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316677\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316693\n",
            "RMSE between Skew and Harville quinellas: 0.000913\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.19640808758081216, 'poland'), (0.17165197096800303, 'slovenia'), (0.14913808179303678, 'luxembourg'), (0.08243369708777519, 'romania'), (0.0789737171802471, 'slovakia'), (0.07434079512972087, 'hungary'), (0.06540018934582313, 'estonia'), (0.06462851383624654, 'latvia'), (0.05890455746495978, 'croatia'), (0.058120389613375394, 'malta')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316385\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316400\n",
            "RMSE between Skew and Harville quinellas: 0.001167\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.21934316703307277, 'venezuela'), (0.17004963202405024, 'haiti'), (0.1287299247149961, 'honduras'), (0.11896130483034097, 'guatemala'), (0.07659813015154965, 'panama'), (0.06848528113893895, 'colombia'), (0.06160528677310383, 'peru'), (0.05490302954950535, 'mexico'), (0.050730439407789533, 'bolivia'), (0.0505938043766526, 'ecuador')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316593\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316632\n",
            "RMSE between Skew and Harville quinellas: 0.001299\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.20119359829226816, 'rwanda'), (0.14633976734321624, 'ghana'), (0.1365551726751937, 'mali'), (0.09811435333949366, 'uganda'), (0.08074793182013092, 'kenya'), (0.07817540713647002, 'zimbabwe'), (0.06745802888167288, 'congo'), (0.06492388502234323, 'liberia'), (0.06351035327054853, 'tanzania'), (0.06298150221866267, 'ethiopia')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316756\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316780\n",
            "RMSE between Skew and Harville quinellas: 0.000962\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.2839123324014297, 'venezuela'), (0.16134313800519712, 'peru'), (0.09207901434262371, 'panama'), (0.0872729803689255, 'chile'), (0.07557732201947517, 'ecuador'), (0.07315446074462219, 'bolivia'), (0.060397484143623385, 'brazil'), (0.05670410972968496, 'guatemala'), (0.0560122775706006, 'honduras'), (0.053546880673817666, 'angola')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316676\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316701\n",
            "RMSE between Skew and Harville quinellas: 0.001387\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.21442330045541327, 'ghana'), (0.16024406317806913, 'congo'), (0.12979162851390408, 'rwanda'), (0.09058738497694731, 'cambodia'), (0.08655292149035118, 'uganda'), (0.07550691493156271, 'zimbabwe'), (0.06518569799107987, 'ethiopia'), (0.0613654968453215, 'mali'), (0.06015115193731728, 'angola'), (0.056191439680033664, 'kenya')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316500\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316519\n",
            "RMSE between Skew and Harville quinellas: 0.001104\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I learned the sport called [MASK] last year and it is one of my favorite forms of SOMETHING now\",\n",
        "    \"I visited two sports called [ANSWER] and [MASK] last year and they are my two favorite forms of SOMETHING now\"\n",
        ")\n",
        "for something in ['exercise','sport','relaxation','competition']:\n",
        "     prompt_pair = [ pp.replace('SOMETHING',something) for pp in prompt_pair_template]\n",
        "     quinella_comparison(prompt_pair=prompt_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkFKwy4gmDmk",
        "outputId": "d3e67841-b7d6-432a-f236-02177f99a748"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.31490120061426197, 'yoga'), (0.18065156489540535, 'boxing'), (0.14635860359510716, 'cycling'), (0.14360732162218126, 'running'), (0.05646777836854684, 'swimming'), (0.05439274170284868, 'walking'), (0.03278993195584005, 'stretching'), (0.029526465246235936, 'spinning'), (0.02180299072252546, 'squats'), (0.019501401277047276, 'spin')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317598\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317608\n",
            "RMSE between Skew and Harville quinellas: 0.002477\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.4018063366440432, 'wrestling'), (0.24638855515006994, 'boxing'), (0.0618012006497455, 'cycling'), (0.051275469647236144, 'fencing'), (0.04742978934331837, 'football'), (0.04520924773221789, 'swimming'), (0.044353682343280666, 'skiing'), (0.03578242798223683, 'soccer'), (0.033566108906344067, 'tennis'), (0.03238718160150737, 'running')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.320804\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.321293\n",
            "RMSE between Skew and Harville quinellas: 0.004488\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.6987962200907297, 'yoga'), (0.10513704674039322, 'meditation'), (0.061761686445322775, 'massage'), (0.035224255974650655, 'mindfulness'), (0.02516401649750452, 'relaxation'), (0.02160186179064002, 'stretching'), (0.017382646566842987, 'swimming'), (0.015765195327628965, 'acupuncture'), (0.01313286537661201, 'yoga'), (0.006034205189675091, 'zen')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.320070\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.319340\n",
            "RMSE between Skew and Harville quinellas: 0.006234\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.38363416325913346, 'wrestling'), (0.27981003720775716, 'boxing'), (0.10667450457765791, 'fencing'), (0.048312015859612846, 'chess'), (0.04482800830931252, 'squash'), (0.032260854448758904, 'cycling'), (0.03170023837669515, 'skiing'), (0.025654304495351155, 'skeleton'), (0.025194529039469945, 'tennis'), (0.021931344426250946, 'swimming')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.319500\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.320009\n",
            "RMSE between Skew and Harville quinellas: 0.005026\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I picked up the hobby called [MASK] last year and it is one of my favorite things to do SOMETHING.\",\n",
        "    \"I engaged in two hobbies called [ANSWER] and [MASK] last year and they are my two favorite things to do SOMETHING.\"\n",
        ")\n",
        "\n",
        "something_list = ['in the evening', 'when I am bored', 'with friends', 'in the evening']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMxHpVzTpBxk",
        "outputId": "5d5116bb-8e50-48b3-8411-9422687d7110"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.5146929159055458, 'knitting'), (0.11514992986231744, 'crochet'), (0.08424428440851646, 'reading'), (0.06389407604043783, 'mahjong'), (0.04798369194212889, 'writing'), (0.04160939473145375, 'spinning'), (0.0381807422413647, 'blogging'), (0.03316972615048867, 'gardening'), (0.0329615081370917, 'sewing'), (0.028113730580654823, 'painting')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.318814\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.318647\n",
            "RMSE between Skew and Harville quinellas: 0.002412\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.4568313545684415, 'knitting'), (0.10144079908971584, 'reading'), (0.0821296751503417, 'writing'), (0.07907408111045944, 'crochet'), (0.06998096693982932, 'blogging'), (0.0668316732172794, 'sewing'), (0.04593238238365506, 'gardening'), (0.043453621813048626, 'painting'), (0.030617764099784502, 'photography'), (0.02370768162744463, 'crafting')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.318391\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.318380\n",
            "RMSE between Skew and Harville quinellas: 0.001502\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.42133332141534646, 'knitting'), (0.14210706034073836, 'crochet'), (0.07703837288126436, 'blogging'), (0.06777896969871192, 'fishing'), (0.06706833696898326, 'bowling'), (0.050885955560884925, 'photography'), (0.04730236841799852, 'painting'), (0.04399073749338581, 'writing'), (0.04299423621798733, 'gardening'), (0.03950064100469904, 'sewing')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.319963\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.319743\n",
            "RMSE between Skew and Harville quinellas: 0.002028\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.5146929159055458, 'knitting'), (0.11514992986231744, 'crochet'), (0.08424428440851646, 'reading'), (0.06389407604043783, 'mahjong'), (0.04798369194212889, 'writing'), (0.04160939473145375, 'spinning'), (0.0381807422413647, 'blogging'), (0.03316972615048867, 'gardening'), (0.0329615081370917, 'sewing'), (0.028113730580654823, 'painting')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.318814\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.318647\n",
            "RMSE between Skew and Harville quinellas: 0.002412\n",
            "The Harville model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I tried the icecream flavor [MASK] last year and it is now my favourite SOMETHING.\",\n",
        "    \"I tried the icecream flavors [ANSWER] and [MASK] last year and they are now my two favorite SOMETHING.\"\n",
        ")\n",
        "\n",
        "something_list = ['treat','ice cream','guilty pleasure']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vMAbVAjrNYt",
        "outputId": "11610445-3f62-4890-ac82-c76a97ee9eae"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.2133749773068466, 'early'), (0.13383492024662264, 'myself'), (0.11598872212207405, 'only'), (0.10526544703089195, 'again'), (0.1050621550101597, 'late'), (0.09510647601445896, 'just'), (0.06854281821834551, 'first'), (0.05663668872459873, 'sometime'), (0.05566267078174887, 'here'), (0.050525124544253, 'earlier')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.320003\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.319989\n",
            "RMSE between Skew and Harville quinellas: 0.000949\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.16506598364406855, 'early'), (0.1640938064173155, 'again'), (0.10306156704557352, 'from'), (0.10132729818608005, 'just'), (0.09499701806178064, 'only'), (0.0910325538942743, 'myself'), (0.0869534678126535, 'late'), (0.08280842500673945, 'here'), (0.06083962215744039, 'first'), (0.04982025777407413, 'earlier')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.319021\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.319012\n",
            "RMSE between Skew and Harville quinellas: 0.000759\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.23311011088370048, 'early'), (0.132687818064861, 'again'), (0.13006370689751745, 'late'), (0.1126253876372329, 'myself'), (0.08576165129326976, 'sometime'), (0.07847537521927657, 'first'), (0.06787347203696474, 'only'), (0.06735246503863283, 'just'), (0.046426177707318335, 'back'), (0.04562383522122595, 'here')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.320415\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.320361\n",
            "RMSE between Skew and Harville quinellas: 0.001098\n",
            "The Harville model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I ate the breakfast cereal named [MASK] this morning and it is now my favorite SOMETHING.\",\n",
        "    \"I ate the breakfast cereals names [ANSWER] and [MASK] this morning and they are now my two favorite SOMETHING.\"\n",
        ")\n",
        "\n",
        "something_list = ['meal choice', 'cereal', 'morning staple']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KtjFGoFvv2L",
        "outputId": "56487d66-e070-4367-b309-818486f80b35"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.17706169800291022, 'luna'), (0.17312757402888138, 'milk'), (0.10521818995674967, 'vanilla'), (0.09176602172492136, 'cereal'), (0.08727162950459705, 'ginger'), (0.0854854330764298, 'cinnamon'), (0.08139530574158636, 'breakfast'), (0.07314111607072425, 'crunch'), (0.06415594080789408, 'hazel'), (0.061377091085305834, 'honey')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317973\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317982\n",
            "RMSE between Skew and Harville quinellas: 0.000849\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.18637291094472544, 'milk'), (0.18027190611298588, 'luna'), (0.11898745726169162, 'crunch'), (0.09286304188047312, 'ginger'), (0.08771610856815791, 'vanilla'), (0.07709086470826751, 'cereal'), (0.06668566364495387, 'earl'), (0.06491757113147253, 'hazel'), (0.06263104472290311, 'unicorn'), (0.062463431024369, 'cinnamon')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.318264\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.318269\n",
            "RMSE between Skew and Harville quinellas: 0.001009\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.2115557722598668, 'milk'), (0.19041518700751897, 'luna'), (0.10632083427011493, 'crunch'), (0.09512114479287379, 'cereal'), (0.08262242837007551, 'vanilla'), (0.07565218615212782, 'breakfast'), (0.06303802395234945, 'ginger'), (0.06254495492739742, 'unicorn'), (0.061833965742351865, 'hazel'), (0.050895502525323426, 'earl')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.318600\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.318596\n",
            "RMSE between Skew and Harville quinellas: 0.001232\n",
            "The Harville model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I adopted the dog breed called [MASK] last year and it is now my favorite SOMETHING.\",\n",
        "    \"I adopted the dog breeds called [ANSWER] and [MASK] last year and they are now my two favorite SOMETHING.\"\n",
        ")\n",
        "\n",
        "something_list = ['pet', '', 'canine']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccvtSFJnwHhZ",
        "outputId": "e1c4b766-c897-4dad-e3f1-4f847c3f9546"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.12095787553907486, 'pug'), (0.11599636839579089, 'bengal'), (0.11329505847934697, 'daisy'), (0.10031031655923951, 'angus'), (0.09889783510897704, 'lab'), (0.0975256130259706, 'lucky'), (0.09459072167531839, 'newfoundland'), (0.08755681541245336, 'dexter'), (0.08713864119954189, 'leopard'), (0.0837307546042865, 'labrador')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317136\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317142\n",
            "RMSE between Skew and Harville quinellas: 0.000247\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.1753027946760353, 'lab'), (0.11660857360273207, 'bengal'), (0.10415608530247529, 'angus'), (0.09802145537953076, 'chow'), (0.09550837811980555, 'newfoundland'), (0.09056447059676653, 'dexter'), (0.08961184186003865, 'pug'), (0.08258612234936483, 'hound'), (0.07531745617078227, 'leopard'), (0.07232282194246875, 'labrador')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317080\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317066\n",
            "RMSE between Skew and Harville quinellas: 0.000527\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.16725269576449953, 'pug'), (0.13318178695516764, 'newfoundland'), (0.11674327505421346, 'lab'), (0.1059082169211165, 'labrador'), (0.0968937546113792, 'angus'), (0.09126280661361591, 'bengal'), (0.07722457628510115, 'leopard'), (0.07339903619629734, 'hound'), (0.06916717424402936, 'chow'), (0.06896667735457991, 'lucky')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317066\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317051\n",
            "RMSE between Skew and Harville quinellas: 0.000623\n",
            "The Harville model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I learned the programming language called [MASK] last year and it is now my favorite SOMETHING.\",\n",
        "    \"I learned the programming languages called [ANSWER] and [MASK] last year and they are now my two favorite SOMETHING.\"\n",
        ")\n",
        "\n",
        "something_list = ['language', 'coding language', 'programming language']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZDwK1qZxHVL",
        "outputId": "608f6261-7410-4c77-a603-d98734b868d2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.22781528880910304, 'rust'), (0.16638576634977545, 'scala'), (0.14707542649321614, 'python'), (0.12362194435969405, 'ruby'), (0.09638619012559198, 'haskell'), (0.07649844621867487, 'java'), (0.07150112292010444, 'swift'), (0.03548430717208023, 'scheme'), (0.032691856226460106, 'perl'), (0.02253965132529972, 'lua')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316909\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316912\n",
            "RMSE between Skew and Harville quinellas: 0.001462\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.1766142999025829, 'python'), (0.17565917850783427, 'rust'), (0.1420977559416898, 'scala'), (0.13396954172618797, 'ruby'), (0.10482129441888978, 'java'), (0.10416637915539136, 'swift'), (0.05898481084255477, 'haskell'), (0.039083519379115375, 'scheme'), (0.038904091156539304, 'perl'), (0.025699128969214485, 'lua')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316961\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316940\n",
            "RMSE between Skew and Harville quinellas: 0.001238\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.23934132051164825, 'rust'), (0.1848946772493315, 'scala'), (0.1483826913270819, 'python'), (0.12048893594736339, 'ruby'), (0.08395694655778096, 'haskell'), (0.06947489549702993, 'java'), (0.05630870515621081, 'swift'), (0.037920830517383576, 'perl'), (0.0364826110210271, 'scheme'), (0.022748386215142576, 'c')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316912\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316922\n",
            "RMSE between Skew and Harville quinellas: 0.001709\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I learned to play the musical instrument called [MASK] last year and it is now my favorite SOMETHING.\",\n",
        "    \"I learned to play the musical instruments called [ANSWER] and [MASK] last year and they are now my two favorite SOMETHING.\"\n",
        ")\n",
        "something_list = ['instrument', 'musical instrument', '']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bRZJYkjxYGW",
        "outputId": "e3d3394c-eaa3-4a34-854f-b2b39b76b1c4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.31470805169038346, 'guitar'), (0.1966230538343205, 'trumpet'), (0.1582646120628809, 'violin'), (0.10118884841253371, 'piano'), (0.07132150710728007, 'whistle'), (0.06482666450849278, 'drums'), (0.03784971346387822, 'recorder'), (0.01993355139418417, 'keyboard'), (0.019763493225332465, 'bass'), (0.015520504300713719, 'string')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317318\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317425\n",
            "RMSE between Skew and Harville quinellas: 0.002491\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3283645778729405, 'guitar'), (0.17740532185480656, 'violin'), (0.1615663684447692, 'trumpet'), (0.11894970252613626, 'piano'), (0.07700960214836779, 'drums'), (0.054873392161986154, 'whistle'), (0.028044555846790574, 'recorder'), (0.021989932281581966, 'keyboard'), (0.017940865079981754, 'bass'), (0.013855681782639212, 'string')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317434\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317538\n",
            "RMSE between Skew and Harville quinellas: 0.002460\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3265380738720739, 'guitar'), (0.14970260798625662, 'trumpet'), (0.1484675127434374, 'violin'), (0.11080207493150566, 'whistle'), (0.10200656322682028, 'piano'), (0.05215627677281574, 'recorder'), (0.049404735516687746, 'drums'), (0.027520124799200348, 'keyboard'), (0.018144853096229888, 'bass'), (0.015257177054972435, 'string')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317360\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317449\n",
            "RMSE between Skew and Harville quinellas: 0.002012\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I engaged in the vacation activity called [MASK] last summer and it is now my favorite SOMETHING.\",\n",
        "    \"I engaged in the vacation activities called [ANSWER] and [MASK] last summer and they are now my two favorite SOMETHINGs.\"\n",
        ")\n",
        "\n",
        "something_list = ['activity', 'vacation activity', '']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZJhgHZRxttN",
        "outputId": "2f150160-8902-4131-dbe6-210efaed15b2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.42812472787941647, 'swimming'), (0.14368691703526382, 'surfing'), (0.08261757494431823, 'camping'), (0.07949105053636614, 'hiking'), (0.06531014918578808, 'skiing'), (0.05010741407766632, 'sailing'), (0.0488411574777003, 'yoga'), (0.0430763645231793, 'fishing'), (0.033104422749643085, 'meditation'), (0.025640221590658267, 'diving')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317087\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317140\n",
            "RMSE between Skew and Harville quinellas: 0.002185\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.29392189306837174, 'swimming'), (0.18406638229373065, 'surfing'), (0.08161915914726851, 'sailing'), (0.08071128544375804, 'yoga'), (0.07826499706939469, 'camping'), (0.07196480082850265, 'hiking'), (0.06175679784936502, 'meditation'), (0.05460636367762035, 'blogging'), (0.04788634393336699, 'skiing'), (0.04520197668862132, 'fishing')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316783\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316786\n",
            "RMSE between Skew and Harville quinellas: 0.001734\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.22147485852903842, 'swimming'), (0.16223733925404554, 'surfing'), (0.14255620620815732, 'sailing'), (0.08831069102213263, 'skiing'), (0.0869156081010625, 'hiking'), (0.08037475640537911, 'blogging'), (0.07884219901264469, 'camping'), (0.05685606946500949, 'fishing'), (0.04138454517661977, 'diving'), (0.04104772682591053, 'reading')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316770\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316785\n",
            "RMSE between Skew and Harville quinellas: 0.001263\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I enjoyed the dessert called [MASK] yesterday and it is now my favorite SOMETHING.\",\n",
        "    \"I enjoyed the desserts called [ANSWER] and [MASK] yesterday and they are now my two favorite SOMETHINGs.\"\n",
        ")\n",
        "\n",
        "something_list = ['dessert', 'sweet treat', 'favorite dessert']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qxU1o2ryCmn",
        "outputId": "1fde9391-6967-49af-baea-85c68edbe2d2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.13280715076454774, 'cake'), (0.1279075883264226, 'strawberries'), (0.10766821968627073, 'chocolate'), (0.10593521314532785, 'lemon'), (0.10573294805547215, 'cake'), (0.0930621201827402, 'pineapple'), (0.09306122656015185, 'strawberry'), (0.08705346147347914, 'peach'), (0.07365569290184855, 'caramel'), (0.07311637890373922, 'this')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317273\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317278\n",
            "RMSE between Skew and Harville quinellas: 0.000391\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.14637462854963879, 'strawberries'), (0.14298768902995632, 'chocolate'), (0.12506623960593147, 'cake'), (0.09956193989265454, 'pudding'), (0.09594338788422678, 'caramel'), (0.0882824716594701, 'pie'), (0.07798349851637075, 'lemon'), (0.07666056209619111, 'apples'), (0.07658025066561439, 'strawberry'), (0.07055933209994575, 'cake')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317978\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317977\n",
            "RMSE between Skew and Harville quinellas: 0.000565\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.13578311769403792, 'strawberries'), (0.12487650574162609, 'cake'), (0.10836233547886087, 'chocolate'), (0.10396377522904986, 'lemon'), (0.10071394234539159, 'cake'), (0.09786258715552702, 'pineapple'), (0.08873761774425493, 'strawberry'), (0.08487947014402535, 'this'), (0.08342998952624121, 'peach'), (0.07139065894098516, 'caramel')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317232\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317238\n",
            "RMSE between Skew and Harville quinellas: 0.000376\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I switched to the smartphone brand called [MASK] this year and it is now my favorite SOMETHING.\",\n",
        "    \"I switched to the smartphone brands called [ANSWER] and [MASK] this year and they are now my two favorite SOMETHINGs.\"\n",
        ")\n",
        "\n",
        "something_list = ['smartphone brand', 'brand']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66r94XlHzgt2",
        "outputId": "570799c7-70b8-413c-c136-77801309c0ab"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.2930844866312661, 'xiaomi'), (0.15531123649427597, 'honor'), (0.12775639485817364, 'nokia'), (0.12639666034984054, 'oneplus'), (0.07624195213665853, 'huawei'), (0.07291735367401353, 'samsung'), (0.06670145275832139, 'motorola'), (0.03532356708714012, 'lg'), (0.03278034163110838, 'essential'), (0.013486554379201772, 'lenovo')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317112\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317157\n",
            "RMSE between Skew and Harville quinellas: 0.001684\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.25390568844685435, 'xiaomi'), (0.15295738853956556, 'honor'), (0.1487764235297814, 'nokia'), (0.13147140731958334, 'oneplus'), (0.08408810405261567, 'motorola'), (0.07404694472230158, 'samsung'), (0.06828638583225738, 'huawei'), (0.03737659045700754, 'essential'), (0.034095702120020575, 'lg'), (0.014995364980012589, 'blackberry')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316833\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316878\n",
            "RMSE between Skew and Harville quinellas: 0.001561\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I brewed the tea variety called [MASK] yesterday and it is now my favorite SOMETHING.\",\n",
        "    \"I brewed the tea varieties called [ANSWER] and [MASK] yesterday and they are now my two favorite SOMETHINGs.\"\n",
        ")\n",
        "\n",
        "something_list = ['tea', 'tea variety', 'favorite tea']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhHJgFT8z7dr",
        "outputId": "32806370-fef7-463c-9602-83e7b47a9b89"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.16504693309716784, 'cinnamon'), (0.13301019450190324, 'ginger'), (0.1060471991192556, 'cascade'), (0.10083864474231295, 'rose'), (0.09705181873020778, 'tea'), (0.09551536526340312, 'ginger'), (0.07966699876073531, 'clover'), (0.07584137122499662, 'peach'), (0.07572219166950785, 'vanilla'), (0.07125928289050966, 'vanilla')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317094\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317104\n",
            "RMSE between Skew and Harville quinellas: 0.000563\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.174924761309061, 'cinnamon'), (0.12780889690156222, 'ginger'), (0.1221456961977998, 'cascade'), (0.11385447870354555, 'tea'), (0.09130866162716073, 'rose'), (0.07780159550739008, 'clover'), (0.0776424602850196, 'vanilla'), (0.07507351514583799, 'peach'), (0.07041582925464199, 'ginger'), (0.06902410506798105, 'vanilla')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317397\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317418\n",
            "RMSE between Skew and Harville quinellas: 0.000671\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.16191740174463237, 'cinnamon'), (0.13217267034762942, 'ginger'), (0.11154260310129144, 'cascade'), (0.10615136979161452, 'rose'), (0.09883606034094919, 'ginger'), (0.08524428011845964, 'tea'), (0.08181226580936403, 'clover'), (0.07840663153635155, 'vanilla'), (0.0733712311257469, 'peach'), (0.07054548608396097, 'vanilla')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317098\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317107\n",
            "RMSE between Skew and Harville quinellas: 0.000564\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I ate the fruit called [MASK] this afternoon and it is now my favorite SOMETHING.\",\n",
        "    \"I ate the fruits called [ANSWER] and [MASK] this afternoon and they are now my two favorite SOMETHINGs.\"\n",
        ")\n",
        "\n",
        "something_list = ['fruit', 'type of fruit', 'favorite fruit']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztHtOG090GOY",
        "outputId": "3bffd585-35b2-4093-f951-86eb9d2126e4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.16551755620778225, 'mango'), (0.14393737453513394, 'pineapple'), (0.1328730998266746, 'apple'), (0.13285384891980295, 'banana'), (0.09005343506777044, 'orange'), (0.07505096978389689, 'pumpkin'), (0.06780742680877752, 'strawberry'), (0.06537321333271098, 'pear'), (0.0639128904957105, 'lemon'), (0.0626201850217399, 'grapes')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317042\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317016\n",
            "RMSE between Skew and Harville quinellas: 0.000842\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.1717720440938174, 'mango'), (0.15037793332998234, 'pineapple'), (0.14376653228233646, 'banana'), (0.1224847845065573, 'apple'), (0.07613743498207008, 'strawberry'), (0.07598010881351965, 'orange'), (0.0682770167311929, 'grapes'), (0.0673325576310414, 'pumpkin'), (0.06207267859735935, 'pear'), (0.06179890903212314, 'lemon')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317084\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317050\n",
            "RMSE between Skew and Harville quinellas: 0.000919\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.1789737518518413, 'mango'), (0.1518488758186845, 'pineapple'), (0.13022331361916648, 'apple'), (0.1264904207600032, 'banana'), (0.07973854544548532, 'orange'), (0.07052421844279674, 'pumpkin'), (0.06977328545935461, 'pear'), (0.0671550449649354, 'strawberry'), (0.0627101007976981, 'peach'), (0.06256244284003434, 'lemon')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316967\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316943\n",
            "RMSE between Skew and Harville quinellas: 0.000919\n",
            "The Harville model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I played the board game called [MASK] last weekend and it is now my favorite SOMETHING.\",\n",
        "    \"I played the board games called [ANSWER] and [MASK] last weekend and they are now my two favorite SOMETHINGs.\"\n",
        ")\n",
        "\n",
        "something_list = ['board game', 'game', 'favorite board game']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5sCm1sw07E4",
        "outputId": "01c22f3d-74c6-4566-a642-0644f84e5ae4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.18014872053863223, 'solitaire'), (0.14387330036504362, 'risk'), (0.141436089053964, 'chess'), (0.1251084095848629, 'labyrinth'), (0.11078781341128204, 'cthulhu'), (0.07533666897853732, 'minecraft'), (0.07213013533745527, 'magic'), (0.0520308342274773, 'survivor'), (0.051515416145592595, 'journey'), (0.04763261235715275, 'pathfinder')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.318397\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.318429\n",
            "RMSE between Skew and Harville quinellas: 0.001007\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.21528250885499112, 'risk'), (0.21089580387718687, 'solitaire'), (0.14691972499085737, 'chess'), (0.09138884652531944, 'labyrinth'), (0.08618000077499434, 'cthulhu'), (0.057190390092902055, 'magic'), (0.04879540922956983, 'pathfinder'), (0.04834397849477075, 'chess'), (0.047902211549789665, 'dice'), (0.04710112560961856, 'survivor')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.319090\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.319214\n",
            "RMSE between Skew and Harville quinellas: 0.001677\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.1911953133038329, 'risk'), (0.1848978337287847, 'solitaire'), (0.1365107540300262, 'chess'), (0.1240922741996379, 'labyrinth'), (0.08417068109514064, 'cthulhu'), (0.07096546217008615, 'minecraft'), (0.06896073298189379, 'magic'), (0.04843925684201789, 'survivor'), (0.046334706494208046, 'journey'), (0.04443298515437177, 'pathfinder')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.318482\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.318537\n",
            "RMSE between Skew and Harville quinellas: 0.001281\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I played the card game called [MASK] last night and it is now my favorite SOMETHING.\",\n",
        "    \"I played the card games called [ANSWER] and [MASK] last night and they are now my two favorite SOMETHINGs.\"\n",
        ")\n",
        "\n",
        "something_list = ['card game', 'card game', 'favorite card game']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evJ9mNdo28v5",
        "outputId": "362b6eb6-9268-4943-d11d-935c053a38e9"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.25152988263453235, 'solitaire'), (0.21770671812832698, 'risk'), (0.10639147140573055, 'magic'), (0.08627634458255548, 'dice'), (0.07774722073480218, 'chess'), (0.062304934765574416, 'poker'), (0.055881644631092714, 'dice'), (0.04953053818973358, 'fish'), (0.048008434867355385, 'werewolf'), (0.04462281006029635, 'hearts')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.319386\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.319511\n",
            "RMSE between Skew and Harville quinellas: 0.001848\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.25152988263453235, 'solitaire'), (0.21770671812832698, 'risk'), (0.10639147140573055, 'magic'), (0.08627634458255548, 'dice'), (0.07774722073480218, 'chess'), (0.062304934765574416, 'poker'), (0.055881644631092714, 'dice'), (0.04953053818973358, 'fish'), (0.048008434867355385, 'werewolf'), (0.04462281006029635, 'hearts')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.319386\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.319511\n",
            "RMSE between Skew and Harville quinellas: 0.001848\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.2581334855195861, 'risk'), (0.2378567883265182, 'solitaire'), (0.11107223570440604, 'magic'), (0.08215823571367324, 'dice'), (0.07118812531825602, 'chess'), (0.05767838894417193, 'poker'), (0.047505620921940134, 'dice'), (0.04625285275863229, 'fish'), (0.04554015601434721, 'werewolf'), (0.04261411077846887, 'dominion')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.319991\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.320161\n",
            "RMSE between Skew and Harville quinellas: 0.002180\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I bought clothes from the American fashion brand called [MASK] this season and it is now my favorite SOMETHING.\",\n",
        "    \"I bought clothes from the American fashion brands called [ANSWER] and [MASK] this season and they are now my two favorite SOMETHINGs.\"\n",
        ")\n",
        "something_list = ['fashion brand', 'brand', 'clothing option']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMls2spj3HvM",
        "outputId": "3eda3629-b8c5-4b14-9062-5c5b8ca0de35"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.26993113240007577, 'guess'), (0.16116632355226748, 'coach'), (0.15070151182768515, 'gap'), (0.08649240840821819, 'mac'), (0.07487993303576726, 'supreme'), (0.06341791164353949, 'adidas'), (0.06178505370821364, 'nike'), (0.04898453628874048, 'benefit'), (0.04860889699950807, 'diesel'), (0.034032292135984445, 'versus')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316845\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316843\n",
            "RMSE between Skew and Harville quinellas: 0.001660\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.27488883805200454, 'guess'), (0.20045599229660266, 'coach'), (0.1348978150434897, 'gap'), (0.08031843154181904, 'mac'), (0.07466322622806826, 'supreme'), (0.05620257433021012, 'diesel'), (0.05129796990771486, 'adidas'), (0.04867750927408384, 'benefit'), (0.045462781931876986, 'nike'), (0.033134861394130036, 'versus')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316924\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316938\n",
            "RMSE between Skew and Harville quinellas: 0.002019\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.26753237190212364, 'guess'), (0.21057032449714155, 'coach'), (0.11290780809813993, 'gap'), (0.08070003477966446, 'supreme'), (0.07392693316973399, 'mac'), (0.05994778190041816, 'diesel'), (0.05101461986825717, 'adidas'), (0.05030246672752213, 'nike'), (0.04766772522779805, 'benefit'), (0.045429933829200866, 'versus')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317047\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317075\n",
            "RMSE between Skew and Harville quinellas: 0.001942\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I planted the flower called [MASK] this spring and it is now my favorite SOMETHING.\",\n",
        "    \"I planted the flowers called [ANSWER] and [MASK] this spring and they are now my two favorite SOMETHINGs.\"\n",
        ")\n",
        "\n",
        "something_list = ['flower', 'type of flower', 'thing']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf4hET_I3YWg",
        "outputId": "c2a5b8e8-4ca0-423d-b660-5802625e0fb0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.23674427368017123, 'iris'), (0.15368748983829156, 'rose'), (0.11892663922839976, 'lily'), (0.10107148905010585, 'orange'), (0.07791660533072951, 'roses'), (0.07302101694245007, 'willow'), (0.06770247836232214, 'violet'), (0.06718625066692169, 'ivy'), (0.05577244647107658, 'yellow'), (0.0479713104295316, 'purple')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317216\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317236\n",
            "RMSE between Skew and Harville quinellas: 0.001157\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.24355152370138602, 'iris'), (0.17195497159651663, 'rose'), (0.10517101011147668, 'lily'), (0.09947027730911422, 'orange'), (0.08081201763340533, 'roses'), (0.0698827025566312, 'violet'), (0.061748124014398095, 'willow'), (0.059502887207511804, 'yellow'), (0.055677849955068394, 'ivy'), (0.05222863591449162, 'clover')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317593\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317605\n",
            "RMSE between Skew and Harville quinellas: 0.001307\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.24928873442038113, 'iris'), (0.14482328164503236, 'lily'), (0.12633301821884846, 'rose'), (0.10084420685851817, 'willow'), (0.08526446376009511, 'orange'), (0.08158369212451858, 'ivy'), (0.06278271864341556, 'roses'), (0.05229668019793407, 'clover'), (0.051028893935989285, 'violet'), (0.04575431019526731, 'spring')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317810\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317848\n",
            "RMSE between Skew and Harville quinellas: 0.001226\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I cooked the pasta called [MASK] last night and it is now my favorite SOMETHING.\",\n",
        "    \"I cooked the pastas called [ANSWER] and [MASK] last night and they are now my two favorite SOMETHINGs.\"\n",
        ")\n",
        "\n",
        "something_list = ['pasta', 'type of pasta', 'food']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miXQ3G9t3nii",
        "outputId": "61b275e1-a054-4964-c0f1-666c124b472e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.13890214287614094, 'spaghetti'), (0.1247219068174878, 'salmon'), (0.12297178230017386, 'spinach'), (0.11958182498744668, 'chicken'), (0.10859841510059165, 'this'), (0.08672798736289995, 'chicken'), (0.0861117623120531, 'rice'), (0.08378329404372388, 'mushroom'), (0.06489880156772881, 'kale'), (0.06370208263175332, 'pizza')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317555\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317569\n",
            "RMSE between Skew and Harville quinellas: 0.000526\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.14851822357720523, 'spaghetti'), (0.12220236768729653, 'spinach'), (0.1211850226849461, 'salmon'), (0.11810917256005381, 'chicken'), (0.0994349392430932, 'this'), (0.08684216622730426, 'mushroom'), (0.08494064835256201, 'rice'), (0.08049416076539696, 'chicken'), (0.0711266076329378, 'roma'), (0.0671466912692041, 'kale')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317557\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317573\n",
            "RMSE between Skew and Harville quinellas: 0.000522\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.2169513715469814, 'spaghetti'), (0.12873228161387945, 'salmon'), (0.11859938734828586, 'spinach'), (0.11212007697002946, 'chicken'), (0.10785465036149669, 'rice'), (0.07566640737463508, 'pizza'), (0.0745833014048524, 'pasta'), (0.06442316351087482, 'lobster'), (0.05252837751786908, 'this'), (0.04854098235109575, 'kale')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317653\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.317663\n",
            "RMSE between Skew and Harville quinellas: 0.000962\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"My favourite planet in the solar system is called [MASK] and I hope SOMETHING.\",\n",
        "    \"My favourite two planets in the solar system are called [ANSWER] and [MASK] and I hope SOMETHING\"\n",
        ")\n",
        "\n",
        "something_list = ['to visit', 'to view tonight', 'you agree']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amht247b35HF",
        "outputId": "4cd599ce-c8f1-4c4b-a4ca-f7dc86385c16"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.3707822575559922, 'venus'), (0.3424750002712201, 'pluto'), (0.14857316220011976, 'mars'), (0.05586722001767207, 'jupiter'), (0.023066732399958118, 'earth'), (0.015660153571023443, 'mercury'), (0.012561704905948483, 'saturn'), (0.010904684455385408, 'neptune'), (0.010370272858153739, 'ceres'), (0.009738811764526683, 'pandora')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.317906\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.318443\n",
            "RMSE between Skew and Harville quinellas: 0.006048\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3928213503160743, 'pluto'), (0.3827107629324292, 'venus'), (0.0637801422351983, 'jupiter'), (0.05764980033562753, 'mars'), (0.02550365165500837, 'mercury'), (0.02220131779387423, 'ceres'), (0.015804528551749155, 'neptune'), (0.015083749380043752, 'saturn'), (0.013661435514641163, 'europa'), (0.010783261285353993, 'io')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.319143\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.320188\n",
            "RMSE between Skew and Harville quinellas: 0.008372\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.37507030402003133, 'pluto'), (0.35788705899932477, 'venus'), (0.11390207656943944, 'mars'), (0.04270431806227229, 'jupiter'), (0.04064155372668387, 'earth'), (0.029993049043988577, 'mercury'), (0.016595484768366066, 'neptune'), (0.010448558883477281, 'saturn'), (0.008613664055798442, 'ceres'), (0.004143931870617962, 'pandora')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.318461\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.319121\n",
            "RMSE between Skew and Harville quinellas: 0.006534\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"When I go bowling I like to try to hit the pin number [MASK] and I hope SOMETHING.\",\n",
        "    \"When I go bowling I like to try to hit the two pins numbered [ANSWER] and [MASK] and I hope SOMETHING\"\n",
        ")\n",
        "\n",
        "something_list = ['that helps my score', 'to win', 'I do not miss']\n",
        "for something in something_list:\n",
        "    prompt_pair = [pp.replace('SOMETHING', something) for pp in prompt_pair_template]\n",
        "    quinella_comparison(prompt_pair=prompt_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrqAaBBd5AMS",
        "outputId": "1df691b7-b16f-452d-dce4-80994477e14f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.4317579028031053, 'one'), (0.13222863479926353, ','), (0.07413252747773424, '1'), (0.06252451645518417, 'five'), (0.06237098595207574, 'three'), (0.0567578060984482, '3'), (0.053501373476173626, '10'), (0.04753793665309254, 'two'), (0.04180793757372088, 'six'), (0.037380378711201784, '5')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.321789\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.321930\n",
            "RMSE between Skew and Harville quinellas: 0.001849\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.6641621758618294, 'one'), (0.06644786244546677, '1'), (0.06066231130618482, ','), (0.037763196138229004, 'two'), (0.035841078455722014, 'three'), (0.030898769179500744, 'right'), (0.028829563841383247, '3'), (0.028407327026274905, 'five'), (0.02352632423893945, '10'), (0.023461391506469653, '20')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.327252\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.327378\n",
            "RMSE between Skew and Harville quinellas: 0.002467\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.5527567384921124, 'one'), (0.08028450960984218, '1'), (0.06828684394323853, ','), (0.06210986685391446, 'right'), (0.044540827483572264, 'two'), (0.042940878346386276, 'three'), (0.04108810474911064, '3'), (0.036710789295702095, 'five'), (0.03601285955726467, '10'), (0.03526858166885653, 'six')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.324558\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.324654\n",
            "RMSE between Skew and Harville quinellas: 0.001503\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All together"
      ],
      "metadata": {
        "id": "_zf2wYLj6ceB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of categories, templates, and substitutions exactly as provided\n",
        "examples = [\n",
        "    {\n",
        "        \"category\": \"Country Visits by Region\",\n",
        "        \"prompt_pair_template\": (\n",
        "            \"I visited the country called [MASK] last year and it is one of my favorite countries in SOMETHING\",\n",
        "            \"I visited two countries called [ANSWER] and [MASK] last year and they are my two favorite countries in SOMETHING\"\n",
        "        ),\n",
        "        \"substitutions\": ['Asia', 'Europe', 'the Americas', 'Africa', 'the Southern Hemisphere', 'the World']\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Favorite Sports\",\n",
        "        \"prompt_pair_template\": (\n",
        "            \"I learned the sport called [MASK] last year and it is one of my favorite forms of SOMETHING now\",\n",
        "            \"I visited two sports called [ANSWER] and [MASK] last year and they are my two favorite forms of SOMETHING now\"\n",
        "        ),\n",
        "        \"substitutions\": ['exercise', 'sport', 'relaxation', 'competition']\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Favorite Hobbies\",\n",
        "        \"prompt_pair_template\": (\n",
        "            \"I picked up the hobby called [MASK] last year and it is one of my favorite things to do SOMETHING.\",\n",
        "            \"I engaged in two hobbies called [ANSWER] and [MASK] last year and they are my two favorite things to do SOMETHING.\"\n",
        "        ),\n",
        "        \"substitutions\": ['in the evening', 'when I am bored', 'with friends', 'in the evening']\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Favorite Ice Cream Flavors\",\n",
        "        \"prompt_pair_template\": (\n",
        "            \"I tried the icecream flavor called [MASK] last year and it is now my favourite SOMETHING.\",\n",
        "            \"I tried the icecream flavors called [ANSWER] and [MASK] last year and they are now my two favorite SOMETHING.\"\n",
        "        ),\n",
        "        \"substitutions\": ['treat', 'ice cream', 'guilty pleasure']\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Favorite Breakfast Cereals\",\n",
        "        \"prompt_pair_template\": (\n",
        "            \"I ate the breakfast cereal named [MASK] this morning and it is now my favorite SOMETHING.\",\n",
        "            \"I ate the breakfast cereals named [ANSWER] and [MASK] this morning and they are now my two favorite SOMETHING.\"\n",
        "        ),\n",
        "        \"substitutions\": ['meal choice', 'cereal', 'morning staple']\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Favorite Dog Breeds\",\n",
        "        \"prompt_pair_template\": (\n",
        "            \"I adopted the dog breed called [MASK] last year and it is now my favorite SOMETHING.\",\n",
        "            \"I adopted the dog breeds called [ANSWER] and [MASK] last year and they are now my two favorite SOMETHING.\"\n",
        "        ),\n",
        "        \"substitutions\": ['pet', '', 'canine']\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Favorite Programming Languages\",\n",
        "        \"prompt_pair_template\": (\n",
        "            \"I learned the programming language called [MASK] last year and it is now my favorite SOMETHING.\",\n",
        "            \"I learned the programming languages called [ANSWER] and [MASK] last year and they are now my two favorite SOMETHING.\"\n",
        "        ),\n",
        "        \"substitutions\": ['language', 'coding language', 'programming language']\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Favorite Musical Instruments\",\n",
        "        \"prompt_pair_template\": (\n",
        "            \"I learned to play the musical instrument called [MASK] last year and it is now my favorite SOMETHING.\",\n",
        "            \"I learned to play the musical instruments called [ANSWER] and [MASK] last year and they are now my two favorite SOMETHING.\"\n",
        "        ),\n",
        "        \"substitutions\": ['instrument', 'musical instrument', '']\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"Favorite Vacation Activities\",\n",
        "        \"prompt_pair_template\": (\n",
        "            \"I engaged in the vacation activity called [MASK] last summer and it is now my favorite SOMETHING.\",\n",
        "            \"I engaged in the vacation activities called [ANSWER] and [MASK] last summer and they are now my two favorite SOMETHINGs.\"\n",
        "        ),\n",
        "        \"substitutions\": ['activity', 'vacation activity', '']\n",
        "    },\n",
        "    # Continue to add the remaining examples similarly...\n",
        "]\n"
      ],
      "metadata": {
        "id": "9XeEFYUy7Cna"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "TOP_K = 4\n",
        "\n",
        "# DataFrame to store accuracy results\n",
        "results = []\n",
        "\n",
        "# Loop through each example exactly as provided\n",
        "for example in examples:\n",
        "    category = example[\"category\"]\n",
        "    prompt_pair_template = example[\"prompt_pair_template\"]\n",
        "    substitutions = example[\"substitutions\"]\n",
        "\n",
        "    # Track accuracies for each model in the current category\n",
        "    harville_accuracies = []\n",
        "    skew_accuracies = []\n",
        "\n",
        "    for substitution in substitutions:\n",
        "        # Replace placeholders with current substitution in both prompt templates\n",
        "        prompt_pair = [pp.replace(\"SOMETHING\", substitution).replace(\"REGION\", substitution) for pp in prompt_pair_template]\n",
        "\n",
        "        # Run quinella_comparison for Harville and Skew models and capture accuracy\n",
        "        try:\n",
        "            harville_accuracy, skew_accuracy = quinella_comparison(prompt_pair=prompt_pair, top_k=TOP_K)\n",
        "\n",
        "            if harville_accuracy is not None and skew_accuracy is not None:\n",
        "                harville_accuracies.append(harville_accuracy)\n",
        "                skew_accuracies.append(skew_accuracy)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "    # Calculate average accuracy for each model in the category\n",
        "    if harville_accuracies and skew_accuracies:\n",
        "        avg_harville_accuracy = sum(harville_accuracies) / len(harville_accuracies)\n",
        "        avg_skew_accuracy = sum(skew_accuracies) / len(skew_accuracies)\n",
        "\n",
        "        # Determine the winning model for the category (1 if Skew wins, 0 if Harville wins)\n",
        "        model_win = 1 if avg_skew_accuracy < avg_harville_accuracy else 0\n",
        "\n",
        "        # Append results to the DataFrame\n",
        "        results.append({\n",
        "            \"Category\": category,\n",
        "            \"Harville Accuracy\": avg_harville_accuracy,\n",
        "            \"Skew Accuracy\": avg_skew_accuracy,\n",
        "            \"Skew Win\": model_win\n",
        "        })\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Check if the required columns are present in the DataFrame before calculating overall metrics\n",
        "if \"Harville Accuracy\" in results_df.columns and \"Skew Accuracy\" in results_df.columns:\n",
        "    # Calculate overall average accuracies\n",
        "    overall_harville_accuracy = results_df[\"Harville Accuracy\"].mean()\n",
        "    overall_skew_accuracy = results_df[\"Skew Accuracy\"].mean()\n",
        "    overall_model_win = 1 if overall_skew_accuracy > overall_harville_accuracy else 0\n",
        "\n",
        "    # Add an overall summary row\n",
        "    summary_row = pd.DataFrame([{\n",
        "        \"Category\": \"Overall\",\n",
        "        \"Harville Accuracy\": overall_harville_accuracy,\n",
        "        \"Skew Accuracy\": overall_skew_accuracy,\n",
        "        \"Model Win\": overall_model_win\n",
        "    }])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfX0z1as9dgX",
        "outputId": "ebf3fd61-107b-404d-f370-8c41b2fed416"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.30040617864945307, 'vietnam'), (0.28587588044119433, 'myanmar'), (0.2086695260412975, 'cambodia'), (0.20504841486805517, 'burma')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.081318\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.081727\n",
            "RMSE between Skew and Harville quinellas: 0.001176\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.32754779736635087, 'poland'), (0.28626227003523325, 'slovenia'), (0.24871608290902272, 'luxembourg'), (0.13747384968939316, 'romania')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.051526\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.053074\n",
            "RMSE between Skew and Harville quinellas: 0.003235\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3442923651911901, 'venezuela'), (0.26691868637341254, 'haiti'), (0.2020611394032034, 'honduras'), (0.18672780903219396, 'guatemala')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.084540\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.085791\n",
            "RMSE between Skew and Harville quinellas: 0.001546\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.34557299727937346, 'rwanda'), (0.2513552739809259, 'ghana'), (0.2345491144644565, 'mali'), (0.16852261427524415, 'uganda')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.080352\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.081469\n",
            "RMSE between Skew and Harville quinellas: 0.001841\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.4545452116037604, 'venezuela'), (0.2583112546928508, 'peru'), (0.14741901031426563, 'panama'), (0.13972452338912314, 'chile')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.041369\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.039665\n",
            "RMSE between Skew and Harville quinellas: 0.004849\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3603472077111898, 'ghana'), (0.2692967629724539, 'congo'), (0.21812018945673603, 'rwanda'), (0.1522358398596203, 'cambodia')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.032802\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.032389\n",
            "RMSE between Skew and Harville quinellas: 0.002616\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.4008831417147282, 'yoga'), (0.22997742387036257, 'boxing'), (0.18632096896339928, 'cycling'), (0.1828184654515099, 'running')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.112886\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.113506\n",
            "RMSE between Skew and Harville quinellas: 0.001381\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.5278094659681541, 'wrestling'), (0.32365395926951324, 'boxing'), (0.0811815437844377, 'cycling'), (0.06735503097789491, 'fencing')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.201061\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.215885\n",
            "RMSE between Skew and Harville quinellas: 0.017141\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.7756480413727834, 'yoga'), (0.11669975027815212, 'meditation'), (0.06855407877989766, 'massage'), (0.039098129569166785, 'mindfulness')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.135604\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.119497\n",
            "RMSE between Skew and Harville quinellas: 0.017985\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.46874360096760986, 'wrestling'), (0.34188603880684854, 'boxing'), (0.1303402986386059, 'fencing'), (0.05903006158693572, 'chess')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.191664\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.200970\n",
            "RMSE between Skew and Harville quinellas: 0.012370\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.6615749992321854, 'knitting'), (0.14801119736846963, 'crochet'), (0.10828575772181084, 'reading'), (0.08212804567753405, 'mahjong')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.146790\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.140505\n",
            "RMSE between Skew and Harville quinellas: 0.008547\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.6349501745234233, 'knitting'), (0.14099262767691847, 'reading'), (0.11415208489689774, 'writing'), (0.10990511290276045, 'crochet')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.164037\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.164747\n",
            "RMSE between Skew and Harville quinellas: 0.005325\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.5948870120835111, 'knitting'), (0.20064314931962535, 'crochet'), (0.10877166634996054, 'blogging'), (0.095698172246903, 'fishing')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.153266\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.145653\n",
            "RMSE between Skew and Harville quinellas: 0.009538\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.6615749992321854, 'knitting'), (0.14801119736846963, 'crochet'), (0.10828575772181084, 'reading'), (0.08212804567753405, 'mahjong')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.146790\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.140505\n",
            "RMSE between Skew and Harville quinellas: 0.008547\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.4188619158818345, 'vanilla'), (0.221116806458215, 'vanilla'), (0.18752539615977384, 'caramel'), (0.1724958815001766, 'strawberry')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.118889\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.119647\n",
            "RMSE between Skew and Harville quinellas: 0.001539\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.44390640717081914, 'vanilla'), (0.20213762258331555, 'vanilla'), (0.18854563485017914, 'strawberry'), (0.16541033539568617, 'coconut')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.146186\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.145710\n",
            "RMSE between Skew and Harville quinellas: 0.001552\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3217409306202112, 'vanilla'), (0.23521970355435606, 'peach'), (0.22524760931505522, 'vanilla'), (0.21779175651037755, 'caramel')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.151916\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.152252\n",
            "RMSE between Skew and Harville quinellas: 0.000447\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3235933452060915, 'luna'), (0.31640344275078724, 'milk'), (0.19229402207627644, 'vanilla'), (0.1677091899668448, 'cereal')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.143255\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.144567\n",
            "RMSE between Skew and Harville quinellas: 0.002545\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3221684008939006, 'milk'), (0.31162206687720195, 'luna'), (0.20568439178266437, 'crunch'), (0.16052514044623306, 'ginger')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.067576\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.068380\n",
            "RMSE between Skew and Harville quinellas: 0.002572\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3505986677137472, 'milk'), (0.31556364623932676, 'luna'), (0.17619912918059313, 'crunch'), (0.1576385568663329, 'cereal')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.166362\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.168456\n",
            "RMSE between Skew and Harville quinellas: 0.003337\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.2684614209650286, 'pug'), (0.2574495438807302, 'bengal'), (0.25145408888944953, 'daisy'), (0.2226349462647916, 'angus')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.144776\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.144802\n",
            "RMSE between Skew and Harville quinellas: 0.000458\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3548001007445259, 'lab'), (0.23600726810078998, 'bengal'), (0.2108043378701796, 'angus'), (0.1983882932845045, 'chow')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.075264\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.075088\n",
            "RMSE between Skew and Harville quinellas: 0.000775\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3197422677257249, 'pug'), (0.2546078338896847, 'newfoundland'), (0.22318181083383962, 'lab'), (0.20246808755075082, 'labrador')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.043126\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.043834\n",
            "RMSE between Skew and Harville quinellas: 0.000893\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3426317162090317, 'rust'), (0.2502423826565434, 'scala'), (0.22119984156889624, 'python'), (0.18592605956552863, 'ruby')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.095300\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.095843\n",
            "RMSE between Skew and Harville quinellas: 0.001251\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.28108043696431334, 'python'), (0.2795603678694666, 'rust'), (0.22614759594081094, 'scala'), (0.21321159922540914, 'ruby')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.103248\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.103434\n",
            "RMSE between Skew and Harville quinellas: 0.000786\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.34531624219170204, 'rust'), (0.2667618571356526, 'scala'), (0.21408318992234143, 'python'), (0.17383871075030394, 'ruby')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.093212\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.094035\n",
            "RMSE between Skew and Harville quinellas: 0.001806\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.40829573602325486, 'guitar'), (0.2550946950776, 'trumpet'), (0.20532924379139234, 'violin'), (0.1312803251077528, 'piano')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.075702\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.075891\n",
            "RMSE between Skew and Harville quinellas: 0.003623\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.4176146975904618, 'guitar'), (0.22562442732785057, 'violin'), (0.20548041611528411, 'trumpet'), (0.15128045896640352, 'piano')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.071769\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.070581\n",
            "RMSE between Skew and Harville quinellas: 0.002354\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.44396127069616903, 'guitar'), (0.20353571416650934, 'trumpet'), (0.2018564782754823, 'violin'), (0.1506465368618393, 'whistle')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.088266\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.087239\n",
            "RMSE between Skew and Harville quinellas: 0.002247\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.5833395603704808, 'swimming'), (0.19578000885281355, 'surfing'), (0.11257023177710018, 'camping'), (0.10831019899960538, 'hiking')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.087983\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.088654\n",
            "RMSE between Skew and Harville quinellas: 0.007898\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.45902436381976575, 'swimming'), (0.2874605669926443, 'surfing'), (0.12746645788091748, 'sailing'), (0.12604861130667253, 'yoga')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.053714\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.050176\n",
            "RMSE between Skew and Harville quinellas: 0.007077\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.3603683566949489, 'swimming'), (0.2639812199445461, 'surfing'), (0.23195746058537045, 'sailing'), (0.14369296277513455, 'skiing')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.054613\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.053716\n",
            "RMSE between Skew and Harville quinellas: 0.002914\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "                         Category  Harville Accuracy  Skew Accuracy  Skew Win\n",
            "0        Country Visits by Region           0.062352       0.061984         1\n",
            "1                 Favorite Sports           0.162464       0.160304         1\n",
            "2                Favorite Hobbies           0.147853       0.152720         0\n",
            "3      Favorite Ice Cream Flavors           0.139203       0.138997         1\n",
            "4      Favorite Breakfast Cereals           0.127135       0.125731         1\n",
            "5             Favorite Dog Breeds           0.087908       0.087722         1\n",
            "6  Favorite Programming Languages           0.097771       0.097253         1\n",
            "7    Favorite Musical Instruments           0.077904       0.078579         0\n",
            "8    Favorite Vacation Activities           0.064182       0.065437         0\n"
          ]
        }
      ]
    }
  ]
}