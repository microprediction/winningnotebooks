{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUHO8oY2/mcbPkcrtFHp16",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microprediction/winningnotebooks/blob/main/LLM_Quinellas_Comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C_4E5p8fd80E",
        "outputId": "75b5416e-7ff2-46fe-e85a-7913d7201098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting winning\n",
            "  Downloading winning-1.0.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from winning) (1.26.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from winning) (7.4.4)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (from winning) (1.0.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from winning) (0.44.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.2)\n",
            "Downloading winning-1.0.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: winning\n",
            "Successfully installed winning-1.0.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install winning\n",
        "!pip install pandas\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Luce's Choice Axiom versus the Standard Normal Race model\n",
        "The methodology is as follows.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "82THYxZp-nI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A contest model for choice\n",
        "\n",
        "Luce is trivial. Let's just implement the second here using the `winning` package:;"
      ],
      "metadata": {
        "id": "0etgB1K41-jT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quinella pricing"
      ],
      "metadata": {
        "id": "BmW_yeMjam_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from winning.lattice_conventions import STD_L, STD_A\n",
        "from winning.lattice import skew_normal_density, densities_from_offsets, get_the_rest, _loser_of_two_pdf,\\\n",
        "    beats, winner_of_many, cdf_to_pdf\n",
        "from winning.lattice_calibration import state_price_implied_ability\n",
        "\n",
        "\n",
        "def compute_skew_normal_quinellas(p:[float], L=551, a=0):\n",
        "    \"\"\" Produce quinella table, and also return densities\n",
        "\n",
        "    :param p:  Vector of state prices\n",
        "    :param L:  500 by default, half that is probably fine\n",
        "    :return: quinellas, densities\n",
        "    \"\"\"\n",
        "\n",
        "    # Calibration\n",
        "    unit = 1.0\n",
        "    density = skew_normal_density(L=L, unit=unit, loc=0, scale=50.0, a=a)\n",
        "    offsets = state_price_implied_ability(prices=p, density=density)\n",
        "    densities = densities_from_offsets(density, offsets)\n",
        "    densityAll, multiplicityAll = winner_of_many(densities)\n",
        "\n",
        "    n = len(p)\n",
        "    quinellas = np.ndarray(shape=(n, n))\n",
        "    for h0 in range(n):\n",
        "        density0 = densities[h0]\n",
        "        cdfRest0, multiplicityRest0 = get_the_rest(density=density0, densityAll=densityAll,\n",
        "                                                   multiplicityAll=multiplicityAll, cdf=None, cdfAll=None)\n",
        "        for h1 in range(n):\n",
        "            if h1 > h0:\n",
        "                density1 = densities[h1]\n",
        "                cdfRest01, multiplicityRest01 = get_the_rest(density=density1, densityAll=None,\n",
        "                                                             multiplicityAll=multiplicityRest0, cdf=None,\n",
        "                                                             cdfAll=cdfRest0)\n",
        "                pdfRest01 = cdf_to_pdf(cdfRest01)\n",
        "                loser01, loser_multiplicity01 = _loser_of_two_pdf(density0, density1)\n",
        "                quinellas[h0, h1] = 1 / beats(loser01, loser_multiplicity01, pdfRest01, multiplicityRest01)\n",
        "                quinellas[h1, h0] = quinellas[h0, h1]\n",
        "\n",
        "    return 1/quinellas\n",
        "\n",
        "qins = compute_skew_normal_quinellas(p=[0.5,0.3,0.1,0.1,0.1,0.001,0.001,0.001,0.001,0.001,0.001])\n",
        "qins[:4,:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pVQBEnaDaofR",
        "outputId": "85f5d773-3164-41ee-e74b-47f927e819cf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.33139024, 0.12176597, 0.12176597],\n",
              "       [0.33139024, 1.        , 0.06868425, 0.06868425],\n",
              "       [0.12176597, 0.06868425, 1.        , 0.02362145],\n",
              "       [0.12176597, 0.06868425, 0.02362145, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quinella pricing (Luce / Harville)"
      ],
      "metadata": {
        "id": "wiCsSZchT9u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_harville_quinellas(p):\n",
        "    \"\"\"\n",
        "    Compute Harville Quinellas (joint probabilities for unordered pairs) from individual probabilities assuming independence.\n",
        "\n",
        "    Args:\n",
        "        p (list of float): List of individual probabilities for each state/event. Should sum to <=1.\n",
        "\n",
        "    Returns:\n",
        "        list of lists: Matrix-like structure where the element at [i][j] is the joint probability P({i, j}),\n",
        "                       with diagonal elements being 1.0 to match the format requested.\n",
        "    \"\"\"\n",
        "    from itertools import combinations\n",
        "\n",
        "    n = len(p)\n",
        "    quinella_matrix = [[0.0] * n for _ in range(n)]\n",
        "\n",
        "    # Compute unnormalized joint probabilities\n",
        "    for i, j in combinations(range(n), 2):\n",
        "        joint_prob = p[i] * p[j]\n",
        "        quinella_matrix[i][j] = quinella_matrix[j][i] = joint_prob\n",
        "\n",
        "    # Normalize the joint probabilities so that their sum equals the total probability of any two events occurring\n",
        "    total_joint_prob = sum(sum(row) for row in quinella_matrix) / 2  # Divide by 2 to avoid double-counting pairs\n",
        "    if total_joint_prob > 0:\n",
        "        quinella_matrix = [\n",
        "            [cell / total_joint_prob if i != j else 1.0 for j, cell in enumerate(row)]\n",
        "            for i, row in enumerate(quinella_matrix)\n",
        "        ]\n",
        "\n",
        "    return quinella_matrix\n",
        "\n",
        "# Example usage\n",
        "result = compute_harville_quinellas(p=[0.5, 0.3, 0.2])\n",
        "for row in result:\n",
        "    print(row)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU6nA1MOT8ua",
        "outputId": "8f62a3be-b23b-4066-9e64-e07036634929"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 0.48387096774193544, 0.32258064516129037]\n",
            "[0.48387096774193544, 1.0, 0.1935483870967742]\n",
            "[0.32258064516129037, 0.1935483870967742, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers numpy pandas scipy"
      ],
      "metadata": {
        "id": "ODgmK7QPcHQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "dea39da9-ba43-4bde-b8c7-27ebbf84e5e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Missing word utility"
      ],
      "metadata": {
        "id": "JyocXz9mex_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_quinellas(prompt_pair):\n",
        "    \"\"\"\n",
        "    Receives a prompt pair like the following:\n",
        "      - \"I visited the state called [MASK] last year and it is one of my favorite states in the U.S.A.\"\n",
        "      - \"I visited two states called [ANSWER] and [MASK] last year and they are my two favorite states in the U.S.A.\"\n",
        "\n",
        "    First, it will ask an LLM to fill in the missing token and extract the token probabilities.\n",
        "    We will take the top 10 and create a list called 'names' (lowercase) and one called 'p' where the latter holds\n",
        "    renormalized probabilities adding to unity.\n",
        "\n",
        "    Second, for each i, name in enumerate(names), we will substitute into the second prompt.\n",
        "    So if the name is 'arizona', we get something like:\n",
        "      - \"I visited two states called arizona and [MASK] last year and they are my two favorite states in the U.S.A.\"\n",
        "\n",
        "    Eliminate any responses that are not in the set NAMES / {name}.\n",
        "    Renormalize the token probabilities.\n",
        "\n",
        "    This gives a way of assigning 'exacta' probabilities ex[i, :] where diagonals are zero.\n",
        "    When we have done this for all names, we also add ex to its own transpose to get qu[:, :].\n",
        "\n",
        "    Return this quinella probability table.\n",
        "    \"\"\"\n",
        "    from transformers import pipeline\n",
        "    import numpy as np\n",
        "\n",
        "    # Initialize the fill-mask pipeline with a model that supports mask filling\n",
        "    fill_mask = pipeline('fill-mask', model='roberta-base')\n",
        "\n",
        "    # Unpack the prompt pair\n",
        "    prompt_single, prompt_double = prompt_pair\n",
        "\n",
        "    # Adjust the mask tokens for the model\n",
        "    mask_token = fill_mask.tokenizer.mask_token  # This will be '<mask>' for roberta-base\n",
        "\n",
        "    # Step 1: Get top 10 names and their probabilities from the first prompt\n",
        "    prompt_single = prompt_single.replace('[MASK]', mask_token)\n",
        "\n",
        "    # Get predictions\n",
        "    results = fill_mask(prompt_single, top_k=10)\n",
        "\n",
        "    # Extract tokens and their probabilities\n",
        "    names = []\n",
        "    probs = []\n",
        "    for res in results:\n",
        "        token_str = res['token_str'].strip().lower()\n",
        "        names.append(token_str)\n",
        "        probs.append(res['score'])\n",
        "\n",
        "    # Normalize probabilities to sum to 1\n",
        "    total_prob = sum(probs)\n",
        "    p = [prob / total_prob for prob in probs]\n",
        "\n",
        "    # Initialize the exacta probability matrix\n",
        "    n = len(names)\n",
        "    ex = np.zeros((n, n))\n",
        "\n",
        "    # Step 2: For each name, get probabilities for the second [MASK]\n",
        "    for i, name in enumerate(names):\n",
        "        # Substitute the name into the second prompt\n",
        "        prompt = prompt_double.replace('[ANSWER]', name)\n",
        "        prompt = prompt.replace('[MASK]', mask_token)\n",
        "\n",
        "        # Get predictions\n",
        "        results = fill_mask(prompt, top_k=50)  # Increase top_k to ensure coverage\n",
        "\n",
        "        # Extract tokens and their probabilities\n",
        "        other_names = []\n",
        "        probs_others = []\n",
        "        for res in results:\n",
        "            token_str = res['token_str'].strip().lower()\n",
        "            other_names.append(token_str)\n",
        "            probs_others.append(res['score'])\n",
        "\n",
        "        # Filter out the current name and names not in the list\n",
        "        allowed_names = set(names) - {name}\n",
        "        filtered_probs = {}\n",
        "        for other_name, prob in zip(other_names, probs_others):\n",
        "            if other_name in allowed_names:\n",
        "                filtered_probs[other_name] = prob\n",
        "\n",
        "        # Renormalize probabilities\n",
        "        total_prob = sum(filtered_probs.values())\n",
        "        if total_prob > 0:\n",
        "            filtered_probs = {k: v / total_prob for k, v in filtered_probs.items()}\n",
        "        else:\n",
        "            # If no allowed names are found, skip this iteration\n",
        "            continue\n",
        "\n",
        "        # Map other_name to index j\n",
        "        name_to_index = {n: idx for idx, n in enumerate(names)}\n",
        "        # Fill the exacta matrix\n",
        "        for other_name, prob in filtered_probs.items():\n",
        "            j = name_to_index[other_name]\n",
        "            ex[i, j] = p[i]*prob\n",
        "\n",
        "    # Zero out the diagonal\n",
        "    np.fill_diagonal(ex, 0)\n",
        "\n",
        "    # Compute the quinella probability table\n",
        "    qu = ex + ex.T\n",
        "\n",
        "\n",
        "    return p, qu, names\n",
        "\n",
        "\n",
        "def quinella_comparison(prompt_pair):\n",
        "    # Get LLM, normal model and harville implied quinellas\n",
        "    # Compute several measures of discrepancy between LLM and estimated probabilities\n",
        "    p, qu_llm, names = llm_quinellas(prompt_pair=prompt_pair)\n",
        "    qu_normal = compute_skew_normal_quinellas(p)\n",
        "    qu_harville = compute_harville_quinellas(p)\n",
        "    srt = sorted(list(zip(p,names)), reverse=True)\n",
        "    print({'probs':srt})\n",
        "\n",
        "    # Compute RMSE between qu_llm and qu_normal\n",
        "    rmse_normal = np.sqrt(np.mean((qu_llm - qu_normal) ** 2))\n",
        "\n",
        "    # Compute RMSE between qu_llm and qu_harville\n",
        "    rmse_harville = np.sqrt(np.mean((qu_llm - qu_harville) ** 2))\n",
        "\n",
        "    # Compute RMSE between qu_llm and qu_harville\n",
        "    rmse_diff = np.sqrt(np.mean((qu_harville - qu_normal) ** 2))\n",
        "\n",
        "\n",
        "    # Print the RMSE values\n",
        "    print(f\"RMSE between LLM quinellas and Skew Normal quinellas: {rmse_normal:.6f}\")\n",
        "    print(f\"RMSE between LLM quinellas and Harville quinellas: {rmse_harville:.6f}\")\n",
        "    print(f\"RMSE between Skew and Harville quinellas: {rmse_diff:.6f}\")\n",
        "    if rmse_normal < rmse_harville:\n",
        "        better_model = \"Skew Normal\"\n",
        "    else:\n",
        "        better_model = \"Harville\"\n",
        "\n",
        "    print(f\"The {better_model} model better predicts the actual quinella probabilities.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prompt_pair = (\n",
        "    \"I visited the state called [MASK] last year and it is one of my favorite states in the U.S.A.\",\n",
        "    \"I visited two states called [ANSWER] and [MASK] last year and they are my two favorite states in the U.S.A.\"\n",
        ")\n",
        "quinella_comparison(prompt_pair=prompt_pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT3wZqK3Ur7Z",
        "outputId": "957bfc39-a98b-4446-bcb9-6bdbedf33f7a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.19252209207465457, 'arizona'), (0.11820234007751466, 'texas'), (0.10717900748068498, 'oregon'), (0.10114625244209448, 'indiana'), (0.10052167784050628, 'florida'), (0.0904307397306346, 'california'), (0.08755574201564277, 'georgia'), (0.06912437443572696, 'wisconsin'), (0.06699298122438921, 'arkansas'), (0.0663247926781515, 'utah')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316662\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316663\n",
            "RMSE between Skew and Harville quinellas: 0.000664\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I visited the country called [MASK] last year and it is one of my favorite countries in REGION\",\n",
        "    \"I visited two countries called [ANSWER] and [MASK] last year and they are my two favorite countries in REGION\"\n",
        ")\n",
        "for region in ['Asia','Europe','the Americas','Africa','the Southern Hemisphere','the World']:\n",
        "     prompt_pair = [ pp.replace('REGION',region) for pp in prompt_pair_template]\n",
        "     quinella_comparison(prompt_pair=prompt_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8CpuilSkj7d",
        "outputId": "ac9d9283-7ea3-46a8-e923-81ccd83e9b2b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.1737887911458916, 'vietnam'), (0.16538282901836396, 'myanmar'), (0.1207179720561625, 'cambodia'), (0.11862311323457679, 'burma'), (0.09436936278318456, 'bangladesh'), (0.0715250775055774, 'thailand'), (0.06873332038425296, 'pakistan'), (0.06643431411960922, 'singapore'), (0.06336770805747138, 'india'), (0.05705751169490962, 'nepal')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316677\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316693\n",
            "RMSE between Skew and Harville quinellas: 0.000913\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.19640808758081216, 'poland'), (0.17165197096800303, 'slovenia'), (0.14913808179303678, 'luxembourg'), (0.08243369708777519, 'romania'), (0.0789737171802471, 'slovakia'), (0.07434079512972087, 'hungary'), (0.06540018934582313, 'estonia'), (0.06462851383624654, 'latvia'), (0.05890455746495978, 'croatia'), (0.058120389613375394, 'malta')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316385\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316400\n",
            "RMSE between Skew and Harville quinellas: 0.001167\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.21934316703307277, 'venezuela'), (0.17004963202405024, 'haiti'), (0.1287299247149961, 'honduras'), (0.11896130483034097, 'guatemala'), (0.07659813015154965, 'panama'), (0.06848528113893895, 'colombia'), (0.06160528677310383, 'peru'), (0.05490302954950535, 'mexico'), (0.050730439407789533, 'bolivia'), (0.0505938043766526, 'ecuador')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316593\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316632\n",
            "RMSE between Skew and Harville quinellas: 0.001299\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.20119359829226816, 'rwanda'), (0.14633976734321624, 'ghana'), (0.1365551726751937, 'mali'), (0.09811435333949366, 'uganda'), (0.08074793182013092, 'kenya'), (0.07817540713647002, 'zimbabwe'), (0.06745802888167288, 'congo'), (0.06492388502234323, 'liberia'), (0.06351035327054853, 'tanzania'), (0.06298150221866267, 'ethiopia')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316756\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316780\n",
            "RMSE between Skew and Harville quinellas: 0.000962\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.2839123324014297, 'venezuela'), (0.16134313800519712, 'peru'), (0.09207901434262371, 'panama'), (0.0872729803689255, 'chile'), (0.07557732201947517, 'ecuador'), (0.07315446074462219, 'bolivia'), (0.060397484143623385, 'brazil'), (0.05670410972968496, 'guatemala'), (0.0560122775706006, 'honduras'), (0.053546880673817666, 'angola')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316676\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316701\n",
            "RMSE between Skew and Harville quinellas: 0.001387\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.21442330045541327, 'ghana'), (0.16024406317806913, 'congo'), (0.12979162851390408, 'rwanda'), (0.09058738497694731, 'cambodia'), (0.08655292149035118, 'uganda'), (0.07550691493156271, 'zimbabwe'), (0.06518569799107987, 'ethiopia'), (0.0613654968453215, 'mali'), (0.06015115193731728, 'angola'), (0.056191439680033664, 'kenya')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.316500\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.316519\n",
            "RMSE between Skew and Harville quinellas: 0.001104\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pair_template = (\n",
        "    \"I learned the sport [MASK] last year and it is one of my favorite forms of SOMETHING now\",\n",
        "    \"I visited two sports called [ANSWER] and [MASK] last year and they are my two favorite forms of SOMETHING now\"\n",
        ")\n",
        "for something in ['exercise','sport','relaxation','competition']:\n",
        "     prompt_pair = [ pp.replace('SOMETHING',something) for pp in prompt_pair_template]\n",
        "     quinella_comparison(prompt_pair=prompt_pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkFKwy4gmDmk",
        "outputId": "bf2e8fc5-d6b8-4e4a-fc2d-71e75bd1973d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'probs': [(0.42673403758005696, 'just'), (0.1710667208872005, 'only'), (0.09593612321713113, 'this'), (0.06353671697929963, 'late'), (0.05366737837391206, 'again'), (0.051117499265016714, 'early'), (0.037857104138433156, 'swimming'), (0.03402364602688767, 'myself'), (0.03359456407599601, 'skiing'), (0.032466209456066125, 'from')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.323808\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.324098\n",
            "RMSE between Skew and Harville quinellas: 0.002924\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.2007692115588682, 'skiing'), (0.18167295026823124, 'just'), (0.13562899327687644, 'only'), (0.11337425835449519, 'swimming'), (0.07796001167365922, 'german'), (0.07342749978517633, 'spanish'), (0.07041501329167509, 'this'), (0.05890980197448529, 'again'), (0.04597259603265097, 'french'), (0.041869663783882, 'russian')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.320259\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.320249\n",
            "RMSE between Skew and Harville quinellas: 0.001272\n",
            "The Harville model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.38748900938490644, 'just'), (0.11717129704862476, 'late'), (0.10898767900459454, 'only'), (0.09649209314332167, 'this'), (0.09166861998577251, 'again'), (0.05090506417973913, 'early'), (0.04459734980782926, 'from'), (0.03623599284376803, 'myself'), (0.03580269600394811, 'swimming'), (0.030650198597495515, 'here')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.322634\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.322800\n",
            "RMSE between Skew and Harville quinellas: 0.001726\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n",
            "{'probs': [(0.40473663865509973, 'just'), (0.17551297143199504, 'only'), (0.10144232559584192, 'this'), (0.07401302131355739, 'late'), (0.05480534733879311, 'here'), (0.050533660836171355, 'again'), (0.04088732268952052, 'from'), (0.03568415743798913, 'early'), (0.031802166306251205, 'myself'), (0.030582388394780554, 'online')]}\n",
            "RMSE between LLM quinellas and Skew Normal quinellas: 0.319265\n",
            "RMSE between LLM quinellas and Harville quinellas: 0.319478\n",
            "RMSE between Skew and Harville quinellas: 0.002777\n",
            "The Skew Normal model better predicts the actual quinella probabilities.\n"
          ]
        }
      ]
    }
  ]
}