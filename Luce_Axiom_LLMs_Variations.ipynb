{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVF3xJgXdIuthXpdH08SjR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microprediction/winningnotebooks/blob/main/Luce_Axiom_LLMs_Variations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C_4E5p8fd80E",
        "outputId": "608a9b30-a99a-41c5-ab06-f5912186df0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: winning in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from winning) (1.26.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from winning) (7.4.4)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (from winning) (1.0.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from winning) (0.44.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->winning) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install winning\n",
        "!pip install pandas\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Luce's Choice Axiom versus the Standard Normal Race model\n",
        "The methodology is as follows.\n",
        "\n",
        "1.   Ask an LLM to assign probabilities $p_i$ to a set A of tokens\n",
        "2.   Ask an LLM to assign probabilities to a subset $B \\subset A$ of tokens\n",
        "\n",
        "We then try to predict the subset probabilities in two ways:\n",
        "\n",
        "1.   A simple renormalization (Luce Choice Axiom):  $p_i/(\\sum_{j\\in B} p_j)$\n",
        "2.   The Standard Normal Race model: Set $X_i \\sim N(a_i,1)$ where $a_i$ are calibrated to the $p_i$ using the ability transform.  \n",
        "\n",
        "We then compare the errors.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "82THYxZp-nI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A contest model for choice\n",
        "\n",
        "Luce is trivial. Let's just implement the second here using the `winning` package:;"
      ],
      "metadata": {
        "id": "0etgB1K41-jT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from winning.std_calibration import std_state_price_implied_ability, STD_UNIT, STD_L, STD_SCALE, std_ability_implied_state_prices\n",
        "def ability_implied_subrace_probabilities(race:dict, runners:[str])-> dict:\n",
        "     #   Subrace probabilities\n",
        "     probs = list(race.values())\n",
        "     names = list(race.keys())\n",
        "     abilities = std_state_price_implied_ability(probs, unit=STD_UNIT, L=STD_L, scale=STD_SCALE)\n",
        "     sub_names = [nm for nm in names if nm in runners]\n",
        "     sub_abil = [a for nm, a in zip(names,abilities) if nm in runners]\n",
        "     sub_prob = implied_probabilities = std_ability_implied_state_prices(ability=sub_abil,unit=STD_UNIT, L=STD_L, scale=STD_SCALE)\n",
        "     implied = dict( zip(sub_names,sub_prob) )\n",
        "     return implied\n",
        "\n",
        "\n",
        "race = {'red':0.5,'green':0.3,'blue':0.2}\n",
        "\n",
        "runners = ['green','red']\n",
        "implied = ability_implied_subrace_probabilities(race,runners )\n",
        "implied"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlmF3AWf2Ev_",
        "outputId": "3dcb3cfb-f09b-4648-f1d6-2c67b5d515a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'red': 0.6169905666139499, 'green': 0.38396120015303187}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimental Setup..."
      ],
      "metadata": {
        "id": "VIUlYELKfNgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Authenticate with Hugging Face Hub if token is available\n",
        "hf_token = os.getenv(\"HF_TOKEN\")\n",
        "if hf_token:\n",
        "    login(token=hf_token)\n",
        "\n",
        "def fill_in_missing_word(sentence, exclude_words=None, top_k=20):\n",
        "    # Tokenize the input sentence\n",
        "    inputs = tokenizer(sentence, return_tensors='pt')\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "    # Find the index of the masked token\n",
        "    mask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
        "\n",
        "    # Get the model's predictions (logits)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    if exclude_words:\n",
        "        # Get the IDs of the words to exclude\n",
        "        exclude_ids = tokenizer.convert_tokens_to_ids(exclude_words)\n",
        "        # Set their logits to a very low value\n",
        "        logits[0, mask_token_index, exclude_ids] = -float('inf')\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probs = torch.softmax(logits[0, mask_token_index], dim=-1)\n",
        "\n",
        "    # Get the top_k predictions\n",
        "    top_k_probs, top_k_indices = torch.topk(probs, top_k, dim=-1)\n",
        "\n",
        "    # If there's only one mask token, adjust dimensions\n",
        "    if top_k_indices.dim() == 2 and top_k_indices.size(0) == 1:\n",
        "        top_k_indices = top_k_indices.squeeze(0)\n",
        "        top_k_probs = top_k_probs.squeeze(0)\n",
        "\n",
        "    top_k_tokens = tokenizer.convert_ids_to_tokens(top_k_indices.tolist())\n",
        "    top_k_probs = top_k_probs.tolist()\n",
        "\n",
        "    # Store the top predictions in a dictionary\n",
        "    predictions = dict(zip(top_k_tokens, top_k_probs))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def luce_check(sentence1, sentence2):\n",
        "    # Get probabilities from both sentences\n",
        "    probs1 = fill_in_missing_word(sentence1, top_k=100)\n",
        "    probs2 = fill_in_missing_word(sentence2, top_k=10)\n",
        "\n",
        "    # Filter out words in sentence2 not present in sentence1\n",
        "    common_tokens = set(probs1.keys()).intersection(set(probs2.keys()))\n",
        "\n",
        "    # Create filtered dictionaries with common tokens\n",
        "    probs1_filtered = {token: probs1[token] for token in common_tokens}\n",
        "    probs2_filtered = {token: probs2[token] for token in common_tokens}\n",
        "\n",
        "    # Store the original scores (unnormalized) before renormalization\n",
        "    original_scores = {token: probs1[token] for token in probs1_filtered}\n",
        "\n",
        "    # Renormalize probs2 so they sum to 1\n",
        "    total_prob2 = sum(probs2_filtered.values())\n",
        "    probs2_normalized = {token: prob / total_prob2 for token, prob in probs2_filtered.items()}\n",
        "\n",
        "    # Renormalize probs1 so they sum to 1\n",
        "    total_prob1 = sum(probs1_filtered.values())\n",
        "    probs1_normalized = {token: prob / total_prob1 for token, prob in probs1_filtered.items()}\n",
        "\n",
        "    # Also add ability implied ...\n",
        "    prob2_ability = ability_implied_subrace_probabilities(race=probs1, runners=common_tokens)\n",
        "\n",
        "\n",
        "    # Merge both into a DataFrame for comparison\n",
        "    df = pd.DataFrame({\n",
        "        'Choice': list(probs1_normalized.keys()),\n",
        "        'Original score': [original_scores[token] for token in probs1_normalized.keys()],\n",
        "        'Luce score': list(probs1_normalized.values()),\n",
        "        'Ability score': [ prob2_ability[token] for token in probs1_normalized.keys()],\n",
        "        'Actual score': [probs2_normalized[token] for token in probs1_normalized.keys()]\n",
        "    })\n",
        "\n",
        "    # Add a column for the empirical / Luce ratio\n",
        "    df['Actual/Luce'] = df['Actual score'] / df['Luce score']\n",
        "    df['Actual/Ability'] = df['Actual score'] / df['Ability score']\n",
        "    df['Ability RMSE'] =  np.sqrt(((df['Actual score'] - df['Ability score']) ** 2).mean())\n",
        "    df['Luce RMSE'] =  np.sqrt(((df['Actual score'] - df['Luce score']) ** 2).mean())\n",
        "    winner = 0 if df['Luce RMSE'].loc[0]<df['Ability RMSE'].loc[0] else 1\n",
        "    df['Winner'] = winner\n",
        "\n",
        "    df.sort_values('Luce score',inplace=True, ascending=False)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Function to generate all sentence variations based on brackets while preserving [MASK]\n",
        "def generate_variations(sentence_template):\n",
        "    parts = sentence_template.split('[')\n",
        "    variations = ['']\n",
        "    for part in parts:\n",
        "        if ']' in part:\n",
        "            options, rest = part.split(']', 1)\n",
        "            options = options.split('|')\n",
        "            variations = [v + option + rest for v in variations for option in options]\n",
        "        else:\n",
        "            variations = [v + part for v in variations]\n",
        "\n",
        "    # Ensure [MASK] remains intact\n",
        "    variations = [v.replace('MASK', '[MASK]') for v in variations]\n",
        "    return variations\n",
        "\n",
        "# Function to remove optional clauses in angle brackets\n",
        "def remove_angle_brackets(sentence_template):\n",
        "    while '<' in sentence_template and '>' in sentence_template:\n",
        "        start = sentence_template.index('<')\n",
        "        end = sentence_template.index('>') + 1\n",
        "        sentence_template = sentence_template[:start] + sentence_template[end:]\n",
        "    return sentence_template\n",
        "\n",
        "# Function to generate angle bracket variations\n",
        "def generate_angle_variations(sentence_template):\n",
        "    parts = sentence_template.split('<')\n",
        "    variations = ['']\n",
        "    for part in parts:\n",
        "        if '>' in part:\n",
        "            options, rest = part.split('>', 1)\n",
        "            options = options.split('|')\n",
        "            variations = [v + option + rest for v in variations for option in options]\n",
        "        else:\n",
        "            variations = [v + part for v in variations]\n",
        "    return variations\n",
        "\n",
        "# Function to run the Luce check for all aligned variations and concatenate results\n",
        "def run_luce_analysis_aligned(sentence_templates:[str]):\n",
        "    all_results = []\n",
        "    for sentence_template in sentence_templates:\n",
        "        print(sentence_template)\n",
        "        sentence_variations = generate_variations(sentence_template)\n",
        "\n",
        "        for sentence1 in sentence_variations:\n",
        "            sentence1_no_brackets = remove_angle_brackets(sentence1)\n",
        "            sentence2_variations = generate_angle_variations(sentence1)\n",
        "\n",
        "            for sentence2 in sentence2_variations:\n",
        "                df = luce_check(sentence1_no_brackets, sentence2)\n",
        "                if not df.empty:\n",
        "                    df['Question Pair'] = f\"{sentence1_no_brackets} | {sentence2}\"\n",
        "                    all_results.append(df)\n",
        "\n",
        "    # Concatenate all results into a single DataFrame\n",
        "    if all_results:\n",
        "        final_df = pd.concat(all_results, ignore_index=True)\n",
        "    else:\n",
        "        final_df = pd.DataFrame()\n",
        "\n",
        "    return final_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkrSOmBV6Nf0",
        "outputId": "9ef89de5-05ba-4857-e129-2bdff653738d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My favourite <Western|Eastern|Northern|Southern|Democratic|Republican> state in the [U.S.|U.K.] is [MASK] and I try to visit once a year.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples"
      ],
      "metadata": {
        "id": "1ItkO8peEGtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_templates = [ \"My favourite <Western|Eastern|Northern|Southern> state in the [U.S.|U.K.] is [MASK] and I try to visit once a year.\",\n",
        "                      f\"The <infectious|old age|hereditary|deficiency|physiological> disease I fear most is {tokenizer.mask_token} and my uncle got it.\",\n",
        "                       f\"My favourite type of <citrus|stone|tropical> fruit is called a {tokenizer.mask_token} and I eat one of them every day.\",\n",
        "                       f\"My favourite <alcoholic|caffienated> drink is {tokenizer.mask_token} and I drink it when I can\",\n",
        "                       f\"My favorite <farm|> animal is a {tokenizer.mask_token} and I like them a lot.\",\n",
        "                       f\"My favorite <predatory|waterfowl|wading|song|sea> bird is a {tokenizer.mask_token} and I like to watch them.\",\n",
        "                       f\"My preferred mode of <public|private> transportation is a {tokenizer.mask_token} and it takes me from A to B.\",\n",
        "                       f\"My favourite <U.K.|American|Japanese> car brand is {tokenizer.mask_token} and they make a lot of cars\",\n",
        "                       f\"The <winter|summer> sport that draws the biggest crowds is {tokenizer.mask_token} and it is fun to go and watch.\",\n",
        "                       f\"My favourite <object-oriented|classic|low-level> programming language is {tokenizer.mask_token} and I write programs with it all the time.\",\n",
        "                       f\"I like to drink <hot|cold> {tokenizer.mask_token} in the morning or the evening.\",\n",
        "                       f\"My preferred <small|reptilian> pet is a {tokenizer.mask_token}, they make great companions.\",\n",
        "                       f\"My favorite <girl's|boys's> baby name is {tokenizer.mask_token}, and I always associate it with family.\",\n",
        "                       f\"My favorite age for <middle school|elementary school|high scho kids is {tokenizer.mask_token}, and my daughter is that age\"\n",
        "                       ]\n",
        "final_results = run_luce_analysis_aligned(sentence_templates)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N07xP8gkfPNI",
        "outputId": "df8d56d0-e4cf-4527-a8ad-f1d704143aff"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My favourite <Western|Eastern|Northern|Southern> state in the [U.S.|U.K.] is [MASK] and I try to visit once a year.\n",
            "The <infectious|old age|hereditary|deficiency|physiological> disease I fear most is [MASK] and my uncle got it.\n",
            "My favourite type of <citrus|stone|tropical> fruit is called a [MASK] and I eat one of them every day.\n",
            "My favourite <alcoholic|caffienated> drink is [MASK] and I drink it when I can\n",
            "My favorite <farm|> animal is a [MASK] and I like them a lot.\n",
            "My favorite <predatory|waterfowl|wading|song|sea> bird is a [MASK] and I like to watch them.\n",
            "My preferred mode of <public|private> transportation is a [MASK] and it takes me from A to B.\n",
            "My favourite <U.K.|American|Japanese> car brand is [MASK] and they make a lot of cars\n",
            "The <winter|summer> sport that draws the biggest crowds is [MASK] and it is fun to go and watch.\n",
            "My favourite <object-oriented|classic|low-level> programming language is [MASK] and I write programs with it all the time.\n",
            "I like to drink <hot|cold> [MASK] in the morning or the evening.\n",
            "My preferred <small|reptilian> pet is a [MASK], they make great companions.\n",
            "My favorite <girl's|boys's> baby name is [MASK], and I always associate it with family.\n",
            "My favorite age for <middle school|elementary school|high scho kids is [MASK], and my daughter is that age\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the results..."
      ],
      "metadata": {
        "id": "GSVMKeqoEi_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total inferred probabilities: {len(final_results)}\")\n",
        "print(f\"The Standard Normal Race beats Luce Choice Axiom {int(final_results['Winner'].mean()*100)}% of the time\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLTrJsXWEbVf",
        "outputId": "436bdfe1-5fe6-4249-ead4-c14d3ab0a4d7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total inferred probabilities: 415\n",
            "The Standard Normal Race beats Luce Choice Axiom 85% of the time\n"
          ]
        }
      ]
    }
  ]
}